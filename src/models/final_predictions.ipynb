{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from scipy.interpolate import interpn\n",
    "from sklearn.preprocessing import robust_scale\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open final data\n",
    "data = pd.read_csv('../../data/processed/final_data.csv')\n",
    "\n",
    "# get the list of columns\n",
    "columns = data.columns\n",
    "positive_columns = [col for col in columns if '+' in col]\n",
    "negative_columns = [col for col in columns if '-' in col]\n",
    "original_columns = [col for col in columns if '+' not in col and '-' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/prwtql5x5sg0mbkxc6508fqm0000gn/T/ipykernel_19169/1086435320.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_training_data['datetime'] = pd.to_datetime(model_training_data['datetime'])\n",
      "/var/folders/bn/prwtql5x5sg0mbkxc6508fqm0000gn/T/ipykernel_19169/1086435320.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_testing_data['datetime'] = pd.to_datetime(model_testing_data['datetime'])\n"
     ]
    }
   ],
   "source": [
    "# use only the training data\n",
    "model_training_data = data[data['dataset'] == 'train']\n",
    "model_testing_data = data[data['dataset'] == 'test']\n",
    "\n",
    "# convert the datetime columns to datetime\n",
    "model_training_data['datetime'] = pd.to_datetime(model_training_data['datetime'])\n",
    "model_testing_data['datetime'] = pd.to_datetime(model_testing_data['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime                           0\n",
      "season                             0\n",
      "holiday                            0\n",
      "workingday                         0\n",
      "weather                            0\n",
      "temp                               0\n",
      "atemp                              0\n",
      "humidity                           0\n",
      "windspeed                          0\n",
      "casual                          6493\n",
      "registered                      6493\n",
      "count                           6493\n",
      "year                               0\n",
      "month                              0\n",
      "day                                0\n",
      "hour                               0\n",
      "dataset                            0\n",
      "count_original                  6493\n",
      "registered_original             6493\n",
      "casual_original                 6493\n",
      "dayofyear                          0\n",
      "weekofyear                         0\n",
      "dayofweek                          0\n",
      "windspeed, +1                      0\n",
      "windspeed, -1                      0\n",
      "atemp, +1                          0\n",
      "atemp, -1                          0\n",
      "humidity, +1                       0\n",
      "humidity, -1                       0\n",
      "holiday, +1                        0\n",
      "holiday, -1                        0\n",
      "workingday, +1                     0\n",
      "workingday, -1                     0\n",
      "weather, +1                        0\n",
      "weather, -1                        0\n",
      "temp, +1                           0\n",
      "temp, -1                           0\n",
      "casual, +1                       262\n",
      "casual, -1                       262\n",
      "registered, +1                   262\n",
      "registered, -1                   262\n",
      "count, +1                        262\n",
      "count, -1                        262\n",
      "windspeed, +2                      0\n",
      "windspeed, -2                      0\n",
      "atemp, +2                          0\n",
      "atemp, -2                          0\n",
      "humidity, +2                       0\n",
      "humidity, -2                       0\n",
      "holiday, +2                        0\n",
      "holiday, -2                        0\n",
      "workingday, +2                     0\n",
      "workingday, -2                     0\n",
      "weather, +2                        0\n",
      "weather, -2                        0\n",
      "temp, +2                           0\n",
      "temp, -2                           0\n",
      "casual, +2                       238\n",
      "casual, -2                       238\n",
      "registered, +2                   238\n",
      "registered, -2                   238\n",
      "count, +2                        238\n",
      "count, -2                        238\n",
      "casual_mean_month                  0\n",
      "casual_std_month                   0\n",
      "casual_median_month                0\n",
      "casual_quantile_25_month           0\n",
      "casual_quantile_75_month           0\n",
      "casual_quantile_10_month           0\n",
      "casual_quantile_90_month           0\n",
      "registered_mean_month              0\n",
      "registered_std_month               0\n",
      "registered_median_month            0\n",
      "registered_quantile_25_month       0\n",
      "registered_quantile_75_month       0\n",
      "registered_quantile_10_month       0\n",
      "registered_quantile_90_month       0\n",
      "count_mean_month                   0\n",
      "count_std_month                    0\n",
      "count_median_month                 0\n",
      "count_quantile_25_month            0\n",
      "count_quantile_75_month            0\n",
      "count_quantile_10_month            0\n",
      "count_quantile_90_month            0\n",
      "casual_mean_day                    0\n",
      "casual_std_day                     0\n",
      "casual_median_day                  0\n",
      "casual_quantile_25_day             0\n",
      "casual_quantile_75_day             0\n",
      "casual_quantile_10_day             0\n",
      "casual_quantile_90_day             0\n",
      "registered_mean_day                0\n",
      "registered_std_day                 0\n",
      "registered_median_day              0\n",
      "registered_quantile_25_day         0\n",
      "registered_quantile_75_day         0\n",
      "registered_quantile_10_day         0\n",
      "registered_quantile_90_day         0\n",
      "count_mean_day                     0\n",
      "count_std_day                      0\n",
      "count_median_day                   0\n",
      "count_quantile_25_day              0\n",
      "count_quantile_75_day              0\n",
      "count_quantile_10_day              0\n",
      "count_quantile_90_day              0\n",
      "weather_2                          0\n",
      "weather_3                          0\n",
      "weather_4                          0\n",
      "season_2                           0\n",
      "season_3                           0\n",
      "season_4                           0\n",
      "dayofweek_1                        0\n",
      "dayofweek_2                        0\n",
      "dayofweek_3                        0\n",
      "dayofweek_4                        0\n",
      "dayofweek_5                        0\n",
      "dayofweek_6                        0\n",
      "hour_1                             0\n",
      "hour_2                             0\n",
      "hour_3                             0\n",
      "hour_4                             0\n",
      "hour_5                             0\n",
      "hour_6                             0\n",
      "hour_7                             0\n",
      "hour_8                             0\n",
      "hour_9                             0\n",
      "hour_10                            0\n",
      "hour_11                            0\n",
      "hour_12                            0\n",
      "hour_13                            0\n",
      "hour_14                            0\n",
      "hour_15                            0\n",
      "hour_16                            0\n",
      "hour_17                            0\n",
      "hour_18                            0\n",
      "hour_19                            0\n",
      "hour_20                            0\n",
      "hour_21                            0\n",
      "hour_22                            0\n",
      "hour_23                            0\n",
      "year_2                             0\n",
      "month_2                            0\n",
      "month_3                            0\n",
      "month_4                            0\n",
      "month_5                            0\n",
      "month_6                            0\n",
      "month_7                            0\n",
      "month_8                            0\n",
      "month_9                            0\n",
      "month_10                           0\n",
      "month_11                           0\n",
      "month_12                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(model_testing_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_period = 0\n",
    "lag_period = 2\n",
    "maximum_day = 20\n",
    "\n",
    "# mask the data from day 3 to 15 of each month using 'datetime' column\n",
    "negative_train_mask = model_training_data['datetime'].apply(lambda x: x.day > lag_period and x.day < maximum_day - test_period)\n",
    "\n",
    "# get the negative training data\n",
    "negative_train_data = model_training_data[negative_train_mask][original_columns + negative_columns].copy()\n",
    "\n",
    "# maske the data from day 5 to 17 of each month using 'datetime' column\n",
    "positive_train_mask = model_training_data['datetime'].apply(lambda x: x.day > test_period and x.day < maximum_day - lag_period)\n",
    "\n",
    "# get the positive training data\n",
    "positive_train_data = model_training_data[positive_train_mask][original_columns + positive_columns].copy()\n",
    "\n",
    "# save the data into a dictionary\n",
    "training_data = {\n",
    "    'positive': {\n",
    "        'X': positive_train_data,\n",
    "        'y': model_testing_data[original_columns + positive_columns]\n",
    "        },\n",
    "    'negative': {\n",
    "        'X': negative_train_data,\n",
    "        'y': model_testing_data[original_columns + negative_columns]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
       "       'atemp', 'humidity', 'windspeed', 'casual',\n",
       "       ...\n",
       "       'windspeed, -2', 'atemp, -2', 'humidity, -2', 'holiday, -2',\n",
       "       'workingday, -2', 'weather, -2', 'temp, -2', 'casual, -2',\n",
       "       'registered, -2', 'count, -2'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 1464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['negative']['X'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each train or test assert there are no NaN values\n",
    "assert not training_data['positive']['X'].isna().values.any()\n",
    "assert not training_data['negative']['X'].isna().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipelines(target_columns, directions, trees, hidden_layer_sizes, max_iter_no_change, categorical_features, rf, mlp, max_iter=2000):\n",
    "    # create a dictionary to store the pipelines\n",
    "    pipelines = {}\n",
    "    \n",
    "\n",
    "    for i, target in enumerate(target_columns):\n",
    "        \n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "        else:\n",
    "            target_name = target\n",
    "\n",
    "        for direction in directions:\n",
    "                \n",
    "            if rf[i]:\n",
    "                # create random forest pipeline for the target and direction\n",
    "                globals()[f'{direction}_{target_name}_pipeline_rf'] = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('regressor', HistGradientBoostingRegressor(max_iter=trees[i], verbose=False, \n",
    "                                                                categorical_features=categorical_features, \n",
    "                                                                max_features=1.0, random_state=0)),\n",
    "                ])\n",
    "\n",
    "                # save the pipeline\n",
    "                pipelines[f'{direction}_{target_name}_pipeline_rf'] = globals()[f'{direction}_{target_name}_pipeline_rf']\n",
    "            \n",
    "            if mlp[i]:\n",
    "                # create MLP pipeline for the target and direction\n",
    "                globals()[f'{direction}_{target_name}_pipeline_mlp'] = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('regressor', XGBRegressor(n_estimators=trees[i]*5, objective='reg:squaredlogerror', \n",
    "                                               n_jobs=-1, colsample_bytree =1.0, device='cpu')),\n",
    "                ])\n",
    "\n",
    "                # save the pipeline\n",
    "                pipelines[f'{direction}_{target_name}_pipeline_mlp'] = globals()[f'{direction}_{target_name}_pipeline_mlp']\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipelines(pipelines, train_data, target_columns, columns_not_to_use, directions, rf, mlp):\n",
    "\n",
    "    #print('\\n\\nFitting pipelines...')\n",
    "    # create a dictionary to store the fitted pipelines\n",
    "    fitted_pipelines = {}\n",
    "\n",
    "    for i, target in enumerate(target_columns):\n",
    "        print(f'Fitting pipelines for {target}')\n",
    "        \n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "            target_name_columns = [col[:-len('_original')] for col in target_columns]\n",
    "        else:\n",
    "            target_name_columns = target_columns\n",
    "            target_name = target\n",
    "\n",
    "        print(f'Maximum of the target: {train_data['positive']['X'][target].max()}')\n",
    "        print(f'Avergae of the target: {train_data['positive']['X'][target].mean()}')\n",
    "        print('')\n",
    "\n",
    "        for direction in directions:\n",
    "\n",
    "            df = train_data[direction]['X'].copy()\n",
    "            target_data = df[target].copy()\n",
    "            #drop_columns = [col for col in columns_not_to_use if col not in target_name_columns[:i]]\n",
    "            drop_columns = columns_not_to_use\n",
    "            \n",
    "\n",
    "            df = df.drop(drop_columns, axis=1)\n",
    "            \n",
    "            #print(f'Columns used: {df.columns}')\n",
    "            \n",
    "            # get the pipelines\n",
    "            if rf[i]:\n",
    "                print(f'Fitting {direction}_{target_name}_pipeline_rf')\n",
    "                pipeline_rf = pipelines[f'{direction}_{target_name}_pipeline_rf']\n",
    "                pipeline_rf.fit(df, target_data)\n",
    "\n",
    "                # save the fitted pipeline\n",
    "                fitted_pipelines[f'{direction}_{target_name}_pipeline_rf'] = pipeline_rf\n",
    "\n",
    "                if i == 0:\n",
    "                    \"\"\"# create a dataframe to store the feature importances\n",
    "                    feature_importances = pd.DataFrame({\n",
    "                        'feature': df.columns,\n",
    "                        'importance': pipeline_rf.named_steps['regressor'].feature_importances_\n",
    "                    })\n",
    "\n",
    "                    # sort the features by importance\n",
    "                    feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "                    # print the feature importances\n",
    "                    print(f'{direction}_{target}_pipeline_rf')\n",
    "                    print(feature_importances)\n",
    "                    print('')\"\"\"\n",
    "                \n",
    "\n",
    "            if mlp[i]:\n",
    "                print(f'Fitting {direction}_{target_name}_pipeline_mlp')\n",
    "                pipeline_mlp = pipelines[f'{direction}_{target_name}_pipeline_mlp']\n",
    "                \n",
    "                # fit the pipeline\n",
    "                pipeline_mlp.fit(df, target_data)\n",
    "\n",
    "                # save the fitted pipeline\n",
    "                fitted_pipelines[f'{direction}_{target_name}_pipeline_mlp'] = pipeline_mlp\n",
    "\n",
    "    \n",
    "                # create a dataframe to store the feature importances\n",
    "                feature_importances = pd.DataFrame({\n",
    "                    'feature': df.columns,\n",
    "                    'importance': pipeline_mlp.named_steps['regressor'].feature_importances_\n",
    "                })\n",
    "\n",
    "                # sort the features by importance\n",
    "                feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "                # remove print limit\n",
    "                pd.set_option('display.max_rows', None)\n",
    "\n",
    "                # print the feature importances\n",
    "                print(f'{direction}_{target}_pipeline_mlp')\n",
    "                print(feature_importances)\n",
    "                print('')\n",
    "\n",
    "    return fitted_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_prediction_with_lags2(df, mask, direction, target, prediction, train_columns):\n",
    "\n",
    "    initial_length = len(df)\n",
    "\n",
    "    if 'original' in target:\n",
    "        target_name = target[:-len('_original')]\n",
    "        target_name_columns = [col[:-len('_original')] for col in train_columns]\n",
    "\n",
    "    else:\n",
    "        target_name = target\n",
    "        target_name_columns = train_columns\n",
    "\n",
    "    data_to_store = df.copy()\n",
    "    # find the unique days in the data\n",
    "    days = data_to_store['datetime'][mask].dt.day.unique()\n",
    "    assert len(days) == 1\n",
    "    day = days[0]\n",
    "\n",
    "    prediction_to_insert = np.array(data_to_store[target_name])\n",
    "    prediction_to_insert[mask] = prediction\n",
    "\n",
    "    data_to_store.loc[:, target_name] = prediction_to_insert\n",
    "\n",
    "    assert not data_to_store[mask][target_name].isna().any()\n",
    "\n",
    "    lags = [1, 2]\n",
    "    sign = '-' if direction == 'negative' else '+'\n",
    "\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        time_delta = pd.Timedelta(days=lag) if direction == 'negative' else pd.Timedelta(days=-lag)\n",
    "        lagged_dates = data_to_store['datetime'][mask] + time_delta\n",
    "        column_name = f'{target_name}, {sign}{lag}'\n",
    "\n",
    "\n",
    "        # create a pandas df\n",
    "        lagged_data = pd.DataFrame({\n",
    "            'datetime': lagged_dates,\n",
    "            'new_col': prediction\n",
    "        })\n",
    "\n",
    "        # merge the data with the lagged data using datetime as index, if the datetime is not in the data, do not add it\n",
    "        data_to_store = data_to_store.merge(lagged_data, on='datetime', how='left')\n",
    "\n",
    "        missing_mask = data_to_store[column_name].isna()\n",
    "        new_values = ~ data_to_store['new_col'].isna()\n",
    "\n",
    "        merge_mask = missing_mask & new_values\n",
    "\n",
    "        #print('Dates to merge:', data_to_store['datetime'][merge_mask])\n",
    "\n",
    "        data_to_store.loc[merge_mask, column_name] = data_to_store['new_col'][merge_mask].copy()\n",
    "        data_to_store = data_to_store.drop(columns = ['new_col'])\n",
    "        \n",
    "        new_day = day + lag if direction == 'negative' else day - lag\n",
    "        new_day_mask = data_to_store['datetime'].dt.day == new_day\n",
    "\n",
    "        if data_to_store[column_name][new_day_mask].isna().sum() > 0:\n",
    "            #print(f'Missing values: ', data_to_store[column_name][new_day_mask].isna().sum())\n",
    "            interpolated_values = data_to_store[column_name][new_day_mask].interpolate(method='linear')\n",
    "            data_to_store.loc[new_day_mask, column_name] = interpolated_values\n",
    "\n",
    "        assert data_to_store[column_name][new_day_mask].isna().sum() == 0\n",
    "        assert len(data_to_store) == initial_length\n",
    "\n",
    "        columns_to_print = [col for col in data_to_store.columns if 'casual' in col]\n",
    "        columns_to_print.append('datetime')\n",
    "        \n",
    "        indices_top_print = np.arange(6327, 6331)\n",
    "\n",
    "        data_to_store = data_to_store.reset_index(drop = True)\n",
    "\n",
    "    # reset the index\n",
    "    data_to_store = data_to_store.reset_index(drop = True)\n",
    "\n",
    "    assert len(data_to_store) == initial_length\n",
    "\n",
    "    return data_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_prediction_with_lags(df, mask, direction, target, prediction, train_columns):\n",
    "    saved_target = target\n",
    "    #print('target: ', saved_target)\n",
    "    # find the column in which the prediction is stored\n",
    "    for col in train_columns:\n",
    "        if target == col:\n",
    "            if 'original' in col:\n",
    "                target = col[:-len('_original')]\n",
    "                cols_to_insert_prediction = [target]\n",
    "            else:\n",
    "                cols_to_insert_prediction = [target]\n",
    "        elif target in col:\n",
    "            cols_to_insert_prediction = [target]\n",
    "        elif col in target:\n",
    "            target = col\n",
    "            col = saved_target\n",
    "            cols_to_insert_prediction = [col]\n",
    "    \n",
    "    \n",
    "    #print('train columns: ', train_columns)\n",
    "    #print('cols to insert prediction: ', cols_to_insert_prediction)\n",
    "    #print('new target: ', target)\n",
    "\n",
    "    prediction_array = np.array(df[saved_target])\n",
    "    #print('length of prediction array: ', len(prediction_array))\n",
    "    prediction_array[mask] = prediction\n",
    "    #print('Nans in prediction array: ', np.isnan(prediction_array).sum())\n",
    "\n",
    "    #print('prediction array: ', prediction_array[:5], prediction_array[-5:], '\\n')\n",
    "\n",
    "    # store the prediction array in the dataframe\n",
    "    for col in cols_to_insert_prediction:\n",
    "        df[col] = prediction_array\n",
    "        #print('Nans in column: ', col, df[col].isnull().sum())\n",
    "        \n",
    "    lags = [1, 2]\n",
    "    sign = '-'\n",
    "\n",
    "    if direction == 'positive':\n",
    "        sign = '+'\n",
    "        lags = [-1, -2]\n",
    "\n",
    "    # get the 'datetime' column for the masked data\n",
    "    datetime = df['datetime']\n",
    "    #print('datetime: ', datetime[:5], datetime[-5:], '\\n')\n",
    "    datetime_masked = df[mask]['datetime']\n",
    "\n",
    "    for lag in lags:\n",
    "        #print('lag: ', lag)\n",
    "        # get the lagged 'datetime' column\n",
    "        lagged_datetime = datetime_masked + pd.DateOffset(days=lag)\n",
    "        print('lagged datetime: ', lagged_datetime[:5], lagged_datetime[-5:], '\\n')\n",
    "        print('datetime masked: ', datetime_masked[:5], datetime_masked[-5:], '\\n')\n",
    "\n",
    "        # get the mask for lagged time\n",
    "        lagged_mask = lagged_datetime.isin(datetime)\n",
    "        #print('lagged mask: ', lagged_mask[:5], lagged_mask[-5:])\n",
    "        #print('total lagged mask: ', lagged_mask.sum(), '\\n')\n",
    "\n",
    "        # get the mask for the lagged 'datetime' column\n",
    "        datetime_mask =  datetime.isin(lagged_datetime)\n",
    "        #print('datetime mask: ', datetime_mask[:5], datetime_mask[-5:])\n",
    "        #print('total datetime mask: ', datetime_mask.sum(), '\\n')\n",
    "\n",
    "        #print('subset of lagged datetime: ', lagged_datetime[lagged_mask][:5], lagged_datetime[lagged_mask][-5:], '\\n')\n",
    "        #print('subset of datetime: ', datetime[datetime_mask][:5], datetime[datetime_mask][-24:18], '\\n')\n",
    "\n",
    "        # assert the number of elements in the lagged mask is equal to the number of elements in the datetime mask\n",
    "        assert lagged_mask.sum() == datetime_mask.sum()\n",
    "\n",
    "        if lagged_mask.sum() > 0:\n",
    "            \n",
    "            print('Inserting prediction for lag: ', lag, ' in coumns: ', cols_to_insert_prediction)\n",
    "            prediction_to_store = prediction[lagged_mask]\n",
    "            #print(f'Predictions inserted from datetime: {lagged_datetime[lagged_mask].iloc[0]} to {lagged_datetime[lagged_mask].iloc[-1]}')\n",
    "            print('prediction to store: ', prediction_to_store[:5], prediction_to_store[-5:], '\\n')\n",
    "            # insert the prediction into the dataframe subsetted by the lagged mask\n",
    "\n",
    "            lagged_col = f'{target}, '+sign+str(abs(lag))\n",
    "\n",
    "            #print('lagged col: ', lagged_col)\n",
    "            # print df.loc with datetime column too\n",
    "            #print(df.loc[datetime_mask, [col for col in df.columns if 'datetime' in col or target in col]])\n",
    "            len_prediction = len(prediction_to_store)\n",
    "            len_space_to_insert = len(df.loc[datetime_mask, lagged_col])\n",
    "\n",
    "            # assert the length of the prediction to store is equal to the length of the space to insert\n",
    "            assert len_prediction == len_space_to_insert\n",
    "            \n",
    "            df.loc[datetime_mask, lagged_col] = prediction_to_store\n",
    "            #print(df.loc[datetime_mask, [col for col in df.columns if 'datetime' in col or target in col]])\n",
    "\n",
    "            sample_index = 17215\n",
    "            #print(df.loc[sample_index, [col for col in df.columns if 'datetime' in col or target in col]])\n",
    "\n",
    "            assert df.loc[datetime_mask, lagged_col].isnull().sum() == 0\n",
    "            print('\\n\\n')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pipelines(fitted_pipelines, training_data, \n",
    "                        train_columns, test_columns, \n",
    "                        columns_not_to_use, test_period, \n",
    "                        maximum_day, directions, rf=True, mlp=False):\n",
    "    \n",
    "    print('\\nPredicting pipelines...')\n",
    "\n",
    "    # create a dictionary to store the predictions\n",
    "    predictions = {}\n",
    "    dataframes = {}\n",
    "\n",
    "    for direction in directions:\n",
    "\n",
    "        for i, target in enumerate(test_columns):\n",
    "            if 'original' in target:\n",
    "                target_name = target[:-len('_original')]\n",
    "                target_name_columns = [col[:-len('_original')] for col in train_columns]\n",
    "            else:\n",
    "                target_name_columns = train_columns\n",
    "                target_name = target\n",
    "\n",
    "        df = training_data[direction]['y'].copy()\n",
    "        #drop_columns =  [col for col in columns_not_to_use if col not in target_name_columns[:i]]\n",
    "        drop_columns = [col for col in columns_not_to_use if col != 'datetime']\n",
    "\n",
    "        # set the target column to NaN\n",
    "        df[target] = np.nan\n",
    "        #print('Initial nan values: ', df[target].isna().sum())\n",
    "\n",
    "        if direction == 'negative':\n",
    "            start_day = 20\n",
    "        elif direction == 'positive':\n",
    "            start_day = 31\n",
    "\n",
    "        day = start_day\n",
    "        days_predicted = 0\n",
    "\n",
    "        while days_predicted < test_period:\n",
    "\n",
    "            # mask the data to select all rows corresponding to a day of the month equal to start_day\n",
    "            mask = df['datetime'].apply(lambda x: x.day == day)\n",
    "\n",
    "            # convert the mask to a numpy array\n",
    "            mask = mask.values\n",
    "\n",
    "            # get the data\n",
    "            df_days = df[mask]\n",
    "\n",
    "            #print('Number of rows: ', df_days.shape[0])\n",
    "            df_days = df_days.drop(drop_columns, axis=1)\n",
    "\n",
    "            #assert 'datetime' not in drop_columns\n",
    "            \n",
    "            #df_days.interpolate(method='linear', axis=0, inplace=True)\n",
    "            #print('Day: ', day)\n",
    "            \n",
    "            \"\"\"\n",
    "            try:\n",
    "                assert not df_days.isna().values.any()\n",
    "            except:\n",
    "                # print the rows and columns with NaN values\n",
    "                subset = df_days[df_days.isna().any(axis=1)]\n",
    "                columns_with_nan = subset.columns[subset.isna().any()].tolist()\n",
    "\n",
    "                print(f'subset: {subset[columns_with_nan + ['datetime']]}')\n",
    "                raise ValueError('There are NaN values in the data')\"\"\"\n",
    "\n",
    "            \n",
    "            df_days = df_days.drop(columns = ['datetime'])\n",
    "    \n",
    "            #print('Columns used: ', df_days.columns)\n",
    "            #print(f'Missing values: {df_days.isna().sum()}')\n",
    "\n",
    "            for i, target in enumerate(test_columns):\n",
    "                #print(target)\n",
    "                \n",
    "                if day == start_day:\n",
    "                    df[target] = np.nan\n",
    "                \n",
    "                if 'original' in target:\n",
    "                    target_name = target[:-len('_original')]\n",
    "                    target_name_columns = [col[:-len('_original')] for col in train_columns]\n",
    "                else:\n",
    "                    target_name_columns = train_columns\n",
    "\n",
    "                if rf[i]:\n",
    "                    pipeline1 = fitted_pipelines[f'{direction}_{target_name}_pipeline_rf']\n",
    "                if mlp[i]:\n",
    "                    pipeline2 = fitted_pipelines[f'{direction}_{target_name}_pipeline_mlp']\n",
    "\n",
    "                # take the mean of the predictions if both pipelines are used\n",
    "                if rf[i] and mlp[i]:\n",
    "                    prediction1 = pipeline1.predict(df_days)\n",
    "                    prediction2 = pipeline2.predict(df_days)\n",
    "\n",
    "                    # use target statistics to scale the predictions\n",
    "                    prediction = (prediction1 + prediction2) / 2\n",
    "                elif rf[i]:\n",
    "                    prediction = pipeline1.predict(df_days)\n",
    "\n",
    "                elif mlp[i]:\n",
    "                    prediction = pipeline2.predict(df_days)\n",
    "\n",
    "                df = store_prediction_with_lags2(df, mask, direction, target, prediction, train_columns)\n",
    "\n",
    "            #print('')\n",
    "\n",
    "            if direction == 'negative':\n",
    "                day += 1\n",
    "            elif direction == 'positive':\n",
    "                day -= 1\n",
    "            days_predicted += 1\n",
    "\n",
    "        for col in target_name_columns:\n",
    "            prediction = df[col].copy()\n",
    "\n",
    "            original_col = col + '_original'\n",
    "            original_data = training_data[direction]['X'][original_col].copy()\n",
    "\n",
    "            original_mean = original_data.mean()\n",
    "            original_std = original_data.std()\n",
    "        \n",
    "            # mask outliers in the prediction, 2 standard deviations\n",
    "            mask = np.abs(prediction - prediction.mean()) > 2.2 * original_std\n",
    "            \n",
    "            # remove outliers\n",
    "            prediction[mask] = np.nan\n",
    "\n",
    "            # interpolate the missing values\n",
    "            prediction = prediction.interpolate(method='linear')\n",
    "\n",
    "            # assert there are no NaN values\n",
    "            assert not prediction.isna().any()\n",
    "\n",
    "            prediction_mean = prediction.mean()\n",
    "            prediction_std = prediction.std()\n",
    "            \n",
    "            # standardise the prediction\n",
    "            standardised_prediction = (prediction - prediction_mean) / (prediction_std)\n",
    "\n",
    "            # use quantile transformer to standardise the prediction\n",
    "            #standardised_prediction = QuantileTransformer(output_distribution='normal').fit_transform(prediction.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "            # multiply the standardised prediction by the standard deviation of the original data\n",
    "            prediction = standardised_prediction * (original_std) + original_mean\n",
    "\n",
    "            # store the prediction in the dataframe\n",
    "            df.loc[:, col] = prediction\n",
    "\n",
    "            # set negative values to zero\n",
    "            df.loc[df[col] < 0, col] = 0\n",
    "\n",
    "            #assert not prediction.isna().any()\n",
    "            predictions[f'{direction}_{col}'] = prediction\n",
    "\n",
    "        dataframes[direction] = df\n",
    "\n",
    "    return predictions, dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def predict_pipelines(fitted_pipelines, training_data, \\n                        train_columns, test_columns, \\n                        columns_not_to_use, test_period, \\n                        maximum_day, directions, rf=True, mlp=False):\\n    \\n    print('\\nPredicting pipelines...')\\n\\n    #\\xa0create a dictionary to store the predictions\\n    predictions = {}\\n    dataframes = {}\\n\\n    df_positive = training_data['positive']['y'].copy()\\n    df_negative = training_data['negative']['y'].copy()\\n    \\n\\n    for i, target in enumerate(test_columns):\\n        print(f'Predicting pipelines for {target}')\\n\\n        if 'original' in target:\\n            target_name = target[:-len('_original')]\\n            target_name_columns = [col[:-len('_original')] for col in train_columns]\\n        else:\\n            target_name_columns = train_columns\\n            target_name = target\\n        for direction in directions:\\n            #print(f'Direction: {direction}')\\n\\n            # get the y data\\n            if direction == 'positive':\\n                df = df_positive\\n            elif direction == 'negative':\\n                df = df_negative\\n            \\n            drop_columns = drop_columns = [col for col in columns_not_to_use if col not in target_name_columns[:i]]\\n            drop_columns = columns_not_to_use\\n\\n            #\\xa0set the target column to NaN\\n            df[target] = np.nan\\n            #print('Initial nan values: ', df[target].isna().sum())\\n\\n            if direction == 'negative':\\n                start_day = 20\\n            elif direction == 'positive':\\n                start_day = 31\\n\\n            day = start_day\\n            days_predicted = 0\\n\\n            while days_predicted < test_period:\\n                # mask the data to select all rows corresponding to a day of the month equal to start_day\\n                mask = df['datetime'].apply(lambda x: x.day == day)\\n                print('Day: ', day)\\n\\n                # get the data\\n                df_days = df[mask].copy()\\n                #print('Number of rows: ', df_days.shape[0])\\n                df_days = df_days.drop(drop_columns, axis=1)\\n                #print('Columns used: ', df_days.columns)\\n\\n                print(f'Missing values: {df_days.isna().sum()}')\\n                assert not df_days.isna().values.any()\\n                \\n                # get the pipeline\\n                if rf[i]:\\n                    pipeline1 = fitted_pipelines[f'{direction}_{target_name}_pipeline_rf']\\n                if mlp[i]:\\n                    pipeline2 = fitted_pipelines[f'{direction}_{target_name}_pipeline_mlp']\\n\\n                # take the mean of the predictions if both pipelines are used\\n                if rf[i] and mlp[i]:\\n                    prediction1 = pipeline1.predict(df_days)\\n                    prediction2 = pipeline2.predict(df_days)\\n\\n                    #\\xa0use target statistics to scale the predictions\\n                    prediction = (prediction1 + prediction2) / 2\\n                elif rf[i]:\\n                    prediction = pipeline1.predict(df_days)\\n                elif mlp[i]:\\n                    prediction = pipeline2.predict(df_days)\\n\\n                #\\xa0assert the lenght of the prediction is equal to the lenght of the mask\\n                #print('Length of prediction: ', len(prediction))\\n                assert len(prediction) == np.sum(mask)\\n\\n                # store the prediction\\n                df = store_prediction_with_lags(df, mask, direction, target, prediction, train_columns)\\n            \\n                if direction == 'negative':\\n                    day += 1\\n\\n                elif direction == 'positive':\\n                    day -= 1\\n\\n                days_predicted += 1\\n                #print('current nan values: ', df[target].isna().sum())\\n                #print('')\\n\\n            prediction = df[target]\\n            \\n            if prediction.isna().sum() > 0:\\n                #\\xa0print the dates with missing values\\n                print('Dates with missing values: ', df[df[target].isna()]['datetime'])\\n\\n            # assert there are no missing values\\n            assert not prediction.isna().values.any()\\n            #print('\\n\\n')\\n            #\\xa0store the predictions\\n            predictions[f'{direction}_{target_name}'] = prediction\\n\\n            # store the dataframe\\n            dataframes[f'{direction}_{target_name}'] = df\\n\\n    return predictions, dataframes\""
      ]
     },
     "execution_count": 1471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def predict_pipelines(fitted_pipelines, training_data, \n",
    "                        train_columns, test_columns, \n",
    "                        columns_not_to_use, test_period, \n",
    "                        maximum_day, directions, rf=True, mlp=False):\n",
    "    \n",
    "    print('\\nPredicting pipelines...')\n",
    "\n",
    "    # create a dictionary to store the predictions\n",
    "    predictions = {}\n",
    "    dataframes = {}\n",
    "\n",
    "    df_positive = training_data['positive']['y'].copy()\n",
    "    df_negative = training_data['negative']['y'].copy()\n",
    "    \n",
    "\n",
    "    for i, target in enumerate(test_columns):\n",
    "        print(f'Predicting pipelines for {target}')\n",
    "\n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "            target_name_columns = [col[:-len('_original')] for col in train_columns]\n",
    "        else:\n",
    "            target_name_columns = train_columns\n",
    "            target_name = target\n",
    "        for direction in directions:\n",
    "            #print(f'Direction: {direction}')\n",
    "\n",
    "            # get the y data\n",
    "            if direction == 'positive':\n",
    "                df = df_positive\n",
    "            elif direction == 'negative':\n",
    "                df = df_negative\n",
    "            \n",
    "            drop_columns = drop_columns = [col for col in columns_not_to_use if col not in target_name_columns[:i]]\n",
    "            drop_columns = columns_not_to_use\n",
    "\n",
    "            # set the target column to NaN\n",
    "            df[target] = np.nan\n",
    "            #print('Initial nan values: ', df[target].isna().sum())\n",
    "\n",
    "            if direction == 'negative':\n",
    "                start_day = 20\n",
    "            elif direction == 'positive':\n",
    "                start_day = 31\n",
    "\n",
    "            day = start_day\n",
    "            days_predicted = 0\n",
    "\n",
    "            while days_predicted < test_period:\n",
    "                # mask the data to select all rows corresponding to a day of the month equal to start_day\n",
    "                mask = df['datetime'].apply(lambda x: x.day == day)\n",
    "                print('Day: ', day)\n",
    "\n",
    "                # get the data\n",
    "                df_days = df[mask].copy()\n",
    "                #print('Number of rows: ', df_days.shape[0])\n",
    "                df_days = df_days.drop(drop_columns, axis=1)\n",
    "                #print('Columns used: ', df_days.columns)\n",
    "\n",
    "                print(f'Missing values: {df_days.isna().sum()}')\n",
    "                assert not df_days.isna().values.any()\n",
    "                \n",
    "                # get the pipeline\n",
    "                if rf[i]:\n",
    "                    pipeline1 = fitted_pipelines[f'{direction}_{target_name}_pipeline_rf']\n",
    "                if mlp[i]:\n",
    "                    pipeline2 = fitted_pipelines[f'{direction}_{target_name}_pipeline_mlp']\n",
    "\n",
    "                # take the mean of the predictions if both pipelines are used\n",
    "                if rf[i] and mlp[i]:\n",
    "                    prediction1 = pipeline1.predict(df_days)\n",
    "                    prediction2 = pipeline2.predict(df_days)\n",
    "\n",
    "                    # use target statistics to scale the predictions\n",
    "                    prediction = (prediction1 + prediction2) / 2\n",
    "                elif rf[i]:\n",
    "                    prediction = pipeline1.predict(df_days)\n",
    "                elif mlp[i]:\n",
    "                    prediction = pipeline2.predict(df_days)\n",
    "\n",
    "                # assert the lenght of the prediction is equal to the lenght of the mask\n",
    "                #print('Length of prediction: ', len(prediction))\n",
    "                assert len(prediction) == np.sum(mask)\n",
    "\n",
    "                # store the prediction\n",
    "                df = store_prediction_with_lags(df, mask, direction, target, prediction, train_columns)\n",
    "            \n",
    "                if direction == 'negative':\n",
    "                    day += 1\n",
    "\n",
    "                elif direction == 'positive':\n",
    "                    day -= 1\n",
    "\n",
    "                days_predicted += 1\n",
    "                #print('current nan values: ', df[target].isna().sum())\n",
    "                #print('')\n",
    "\n",
    "            prediction = df[target]\n",
    "            \n",
    "            if prediction.isna().sum() > 0:\n",
    "                # print the dates with missing values\n",
    "                print('Dates with missing values: ', df[df[target].isna()]['datetime'])\n",
    "\n",
    "            # assert there are no missing values\n",
    "            assert not prediction.isna().values.any()\n",
    "            #print('\\n\\n')\n",
    "            # store the predictions\n",
    "            predictions[f'{direction}_{target_name}'] = prediction\n",
    "\n",
    "            # store the dataframe\n",
    "            dataframes[f'{direction}_{target_name}'] = df\n",
    "\n",
    "    return predictions, dataframes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_training_columns(fitted_pipelines, training_data, train_columns, \n",
    "                                test_columns, columns_not_to_use, directions, rf, mlp):\n",
    "    print('\\nSubstituting training columns...')\n",
    "\n",
    "    df_positive = training_data['positive']['X'].copy()\n",
    "    df_negative = training_data['negative']['X'].copy()\n",
    "\n",
    "    for i, target in enumerate(test_columns):\n",
    "        print(f'Substituting training columns for {target}')\n",
    "\n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "            target_name_columns = [col[:-len('_original')] for col in train_columns]\n",
    "        else:\n",
    "            target_name_columns = train_columns\n",
    "            target_name = target\n",
    "\n",
    "        for direction in directions:\n",
    "\n",
    "            if direction == 'positive':\n",
    "                df = df_positive.copy()\n",
    "            elif direction == 'negative':\n",
    "                df = df_negative.copy()\n",
    "\n",
    "            drop_columns = [col for col in columns_not_to_use if col not in target_name_columns[:i]]\n",
    "            drop_columns = columns_not_to_use\n",
    "\n",
    "            # get the pipeline\n",
    "            if rf[i]:\n",
    "                pipeline1 = fitted_pipelines[f'{direction}_{target_name}_pipeline_rf']\n",
    "            if mlp[i]:\n",
    "                pipeline2 = fitted_pipelines[f'{direction}_{target_name}_pipeline_mlp']\n",
    "\n",
    "            # get the data\n",
    "            df = df.drop(drop_columns, axis=1)\n",
    "\n",
    "            if rf[i] and mlp[i]:\n",
    "                prediction1 = pipeline1.predict(df)\n",
    "                prediction2 = pipeline2.predict(df)\n",
    "\n",
    "                prediction = (prediction1 + prediction2) / 2\n",
    "\n",
    "            elif rf[i]:\n",
    "                prediction = pipeline1.predict(df)\n",
    "            elif mlp[i]:\n",
    "                prediction = pipeline2.predict(df)\n",
    "\n",
    "            print(f'Maximum of the prediction: {prediction.max()}')\n",
    "            print(f'Avergae of the prediction: {prediction.mean()}')\n",
    "\n",
    "            # store the prediction in the df_positive or df_negative\n",
    "            if direction == 'positive':\n",
    "                df_positive[target_name] = prediction\n",
    "            elif direction == 'negative':\n",
    "                df_negative[target_name] = prediction\n",
    "    \n",
    "    # put everything back into the training data\n",
    "    training_data['positive']['X'] = df_positive\n",
    "    training_data['negative']['X'] = df_negative\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_predictions(predictions, training_data, target_columns, directions):\n",
    "\n",
    "    print('\\nMerging predictions...')\n",
    "    \n",
    "    data = training_data.copy()\n",
    "\n",
    "    for target in target_columns:\n",
    "\n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "        else:\n",
    "            target_name = target\n",
    "\n",
    "        target_prediction = np.zeros(data['positive']['y'].shape[0])\n",
    "\n",
    "        for i, direction in enumerate(directions):\n",
    "            print(f'Merging predictions for {direction}_{target_name}')\n",
    "\n",
    "            # get the predictions\n",
    "            prediction = predictions[f'{direction}_{target_name}']\n",
    "            #print('prediction: ', prediction[:5], prediction[-5:], '\\n')\n",
    "\n",
    "            # plot the prediction\n",
    "            #plt.figure(figsize=(10, 5))\n",
    "            #plt.plot(prediction)\n",
    "            #plt.title(f'{direction}_{target_name}')\n",
    "            #plt.show()\n",
    "            #plt.pause(0.1)\n",
    "\n",
    "            df = data[direction]['y'].copy()\n",
    "            #print('shape of df: ', df.shape)\n",
    "\n",
    "            # find all unique months in the 'datetime' column, with same months in different years counting as different months\n",
    "            df['month_year'] = list(zip(df['datetime'].dt.year, df['datetime'].dt.month))\n",
    "\n",
    "            months = df['month_year'].unique()\n",
    "\n",
    "            weights = np.zeros(df.shape[0])\n",
    "            \n",
    "            for month in months:\n",
    "                # mask the data to select all rows corresponding to a month\n",
    "                mask = df['month_year'] == month\n",
    "                if i == 0:\n",
    "                    weights[mask] = np.linspace(1, 0, np.sum(mask))\n",
    "                else:\n",
    "                    weights[mask] = np.linspace(0, 1,  np.sum(mask))\n",
    "\n",
    "            #print('weights: ', weights[:5], weights[-5:], '\\n')\n",
    "            #print('shape of prediction: ', prediction.shape)\n",
    "            #print('shape of total prediction: ', target_prediction.shape)\n",
    "            #print('shape of weights: ', weights.shape)\n",
    "            \n",
    "            # apply the weights to the prediction\n",
    "            target_prediction += prediction * weights\n",
    "\n",
    "        # plot the target prediction\n",
    "        #plt.figure(figsize=(10, 5))\n",
    "        #plt.plot(target_prediction)\n",
    "        #plt.title(f'{target_name}')\n",
    "        #plt.show()\n",
    "        #plt.pause(0.1)\n",
    "\n",
    "        print('Maximum of the target prediction: ', target_prediction.max())\n",
    "        print('Average of the target prediction: ', target_prediction.mean())\n",
    "        print('')\n",
    "        #print('target prediction: ', target_prediction[:5], target_prediction[-5:], '\\n\\n')\n",
    "        # subsitute the target column with the prediction\n",
    "        for direction in directions:\n",
    "            # insert the prediction into the dataframe\n",
    "            #print('target prediction type: ', type(target_prediction))\n",
    "            data[direction]['y'].loc[:, target_name] = np.copy(target_prediction)\n",
    "            #print('Nans in the target prediction: ', np.sum(target_prediction == pd.NA))\n",
    "            \n",
    "            #data[direction]['y'][target] = target_prediction\n",
    "            # assert there are no missing values\n",
    "            #print('Nans in the target prediction: ', data[direction]['y'][target_name].isna().sum())\n",
    "            # print the dates with missing values\n",
    "            #print('Dates with missing values: ', data[direction]['y'][target_name][data[direction]['y'][target_name].isna()])\n",
    "            assert not data[direction]['y'][target_name].isna().values.any()\n",
    "\n",
    "    # print the evaluation metrics\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipelines2(predictions, training_data, target_columns, directions):\n",
    "\n",
    "    data = training_data.copy()\n",
    "\n",
    "    for target in target_columns:\n",
    "\n",
    "        if 'original' in target:\n",
    "            target_name = target[:-len('_original')]\n",
    "        else:\n",
    "            target_name = target\n",
    "\n",
    "        for direction in directions:\n",
    "\n",
    "            # get the y data\n",
    "            y = data[direction]['y'][target].copy()\n",
    "\n",
    "            # get the predictions\n",
    "            prediction = predictions[f'{direction}_{target_name}']\n",
    "\n",
    "            # subsitute the target column with the prediction\n",
    "            data[direction]['y'][target] = prediction\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:  Index(['holiday', 'workingday', 'weather_2', 'weather_3', 'season_2',\n",
      "       'season_3', 'season_4', 'dayofweek_1', 'dayofweek_2', 'dayofweek_3',\n",
      "       'dayofweek_4', 'dayofweek_5', 'dayofweek_6', 'hour_1', 'hour_2',\n",
      "       'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9',\n",
      "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
      "       'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21',\n",
      "       'hour_22', 'hour_23', 'year_2', 'month_2', 'month_3', 'month_4',\n",
      "       'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10',\n",
      "       'month_11', 'month_12'],\n",
      "      dtype='object')\n",
      "Len of categorical features:  48\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1475], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m test_columns \u001b[38;5;241m=\u001b[39m train_columns\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# create the pipelines\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m pipelines \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_pipelines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_iter_no_change\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# fit the pipelines\u001b[39;00m\n\u001b[1;32m     49\u001b[0m fitted_pipelines \u001b[38;5;241m=\u001b[39m fit_pipelines(pipelines, training_data, \n\u001b[1;32m     50\u001b[0m                                  train_columns, columns_not_to_use,\n\u001b[1;32m     51\u001b[0m                                  directions, rf\u001b[38;5;241m=\u001b[39mrf, mlp\u001b[38;5;241m=\u001b[39mmlp)\n",
      "Cell \u001b[0;32mIn[1466], line 18\u001b[0m, in \u001b[0;36mcreate_pipelines\u001b[0;34m(target_columns, directions, trees, hidden_layer_sizes, max_iter_no_change, categorical_features, rf, mlp, max_iter)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m direction \u001b[38;5;129;01min\u001b[39;00m directions:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rf[i]:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# create random forest pipeline for the target and direction\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m---> 18\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mrobust_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m     19\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m'\u001b[39m, HistGradientBoostingRegressor(max_iter\u001b[38;5;241m=\u001b[39mtrees[i], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     20\u001b[0m                                                         categorical_features\u001b[38;5;241m=\u001b[39mcategorical_features, \n\u001b[1;32m     21\u001b[0m                                                         max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     22\u001b[0m         ])\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# save the pipeline\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         pipelines[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3259\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3257\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3174\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3172\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required\u001b[39m\u001b[38;5;132;01m{argtype}\u001b[39;00m\u001b[38;5;124m argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3173\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname, argtype\u001b[38;5;241m=\u001b[39margtype)\n\u001b[0;32m-> 3174\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3176\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[1;32m   3177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'X'"
     ]
    }
   ],
   "source": [
    "columns_not_to_use = ['datetime', 'dataset', 'day', 'month', 'weather', 'year']\n",
    "smoothed_columns = ['casual', 'registered', 'count']\n",
    "original_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "\n",
    "columns_not_to_use = columns_not_to_use + smoothed_columns + original_columns\n",
    "\n",
    "data_sample = training_data['positive']['X'].copy()\n",
    "data_sample = data_sample.drop(columns = columns_not_to_use, axis=1)\n",
    "\n",
    "# shuffle the data\n",
    "data_sample = data_sample.sample(frac=1, random_state=0)\n",
    "data_sample = data_sample[:2000]\n",
    "categorical_features = np.zeros((len(data_sample.columns),), dtype=bool)\n",
    "\n",
    "for col in data_sample.columns:\n",
    "    # check weather only 0 and 1 are present in the column\n",
    "    if len(data_sample[col].unique()) == 2:\n",
    "        # if so, append the column to the list of categorical features\n",
    "        categorical_features[data_sample.columns.get_loc(col)] = True\n",
    "\n",
    "print('Categorical features: ', data_sample.columns[categorical_features])\n",
    "print('Len of categorical features: ', len(data_sample.columns[categorical_features]))\n",
    "\n",
    "\n",
    "directions = ['negative', 'positive']\n",
    "rf = [True, True, True]\n",
    "mlp = [True, True, True]\n",
    "n = 200\n",
    "trees = [n, n, n]\n",
    "max_iter = 2000\n",
    "hidden_layer_sizes = [(150, 150, 150), (250, 250, 250, 250), (200, 200, 200)]\n",
    "max_iter_no_change = [10, 15, 10]\n",
    "test_period = 12\n",
    "lag_period = 2\n",
    "maximum_day = 20\n",
    "\n",
    "\n",
    "train_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "test_columns = train_columns\n",
    "\n",
    "\n",
    "# create the pipelines\n",
    "pipelines = create_pipelines(train_columns, directions, \n",
    "                             trees, hidden_layer_sizes,\n",
    "                             max_iter_no_change, categorical_features,\n",
    "                             rf=rf, mlp=mlp, max_iter=max_iter)\n",
    "\n",
    "# fit the pipelines\n",
    "fitted_pipelines = fit_pipelines(pipelines, training_data, \n",
    "                                 train_columns, columns_not_to_use,\n",
    "                                 directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# predict the pipelines\n",
    "predictions, dataframes = predict_pipelines(fitted_pipelines, training_data, \n",
    "                                            train_columns, test_columns, \n",
    "                                            columns_not_to_use, test_period, \n",
    "                                            maximum_day, directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# evaluate the pipelines\n",
    "training_data_registered = merge_predictions(predictions, training_data, test_columns, directions)\n",
    "\n",
    "# TODO: solve the prediction order doing for the first day all features, for the second day all features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting pipelines for casual_original\n",
      "Maximum of the target: 367.0\n",
      "Avergae of the target: 36.023899887167914\n",
      "\n",
      "Fitting negative_casual_pipeline_rf\n",
      "Fitting negative_casual_pipeline_mlp\n",
      "negative_casual_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "8                          casual    0.587317\n",
      "30             count_median_month    0.014588\n",
      "73                         hour_6    0.012307\n",
      "72                         hour_5    0.011981\n",
      "44          registered_median_day    0.010967\n",
      "29                count_std_month    0.010914\n",
      "34        count_quantile_90_month    0.010580\n",
      "13                      dayofweek    0.010249\n",
      "71                         hour_4    0.009334\n",
      "93                        month_3    0.008864\n",
      "32        count_quantile_75_month    0.008365\n",
      "17       casual_quantile_25_month    0.008094\n",
      "2                      workingday    0.008060\n",
      "117                workingday, -2    0.007772\n",
      "23        registered_median_month    0.007297\n",
      "87                        hour_20    0.007183\n",
      "18       casual_quantile_75_month    0.006772\n",
      "24   registered_quantile_25_month    0.006382\n",
      "37              casual_median_day    0.006240\n",
      "74                         hour_7    0.006228\n",
      "10                           hour    0.005758\n",
      "70                         hour_3    0.005565\n",
      "57                      weather_3    0.005390\n",
      "15               casual_std_month    0.005386\n",
      "55          count_quantile_90_day    0.005373\n",
      "9                            year    0.005310\n",
      "36                 casual_std_day    0.005253\n",
      "21          registered_mean_month    0.005214\n",
      "106                   holiday, -1    0.005203\n",
      "51               count_median_day    0.004990\n",
      "26   registered_quantile_10_month    0.004797\n",
      "69                         hour_2    0.004665\n",
      "50                  count_std_day    0.004645\n",
      "31        count_quantile_25_month    0.004581\n",
      "14              casual_mean_month    0.004571\n",
      "11                      dayofyear    0.004460\n",
      "118                   weather, -2    0.004426\n",
      "110                    casual, -1    0.004303\n",
      "49                 count_mean_day    0.004272\n",
      "16            casual_median_month    0.004266\n",
      "60                       season_3    0.004251\n",
      "75                         hour_8    0.004235\n",
      "35                casual_mean_day    0.004035\n",
      "105                  humidity, -1    0.003669\n",
      "3                         weather    0.003583\n",
      "5                           atemp    0.003575\n",
      "0                          season    0.003560\n",
      "33        count_quantile_10_month    0.003546\n",
      "19       casual_quantile_10_month    0.003408\n",
      "6                        humidity    0.003356\n",
      "28               count_mean_month    0.003352\n",
      "113                 windspeed, -2    0.003321\n",
      "95                        month_5    0.003278\n",
      "53          count_quantile_75_day    0.003204\n",
      "119                      temp, -2    0.003126\n",
      "68                         hour_1    0.003056\n",
      "94                        month_4    0.003010\n",
      "7                       windspeed    0.002983\n",
      "56                      weather_2    0.002974\n",
      "89                        hour_22    0.002907\n",
      "104                     atemp, -1    0.002875\n",
      "115                  humidity, -2    0.002858\n",
      "121                registered, -2    0.002851\n",
      "108                   weather, -1    0.002834\n",
      "111                registered, -1    0.002821\n",
      "114                     atemp, -2    0.002797\n",
      "4                            temp    0.002705\n",
      "112                     count, -1    0.002705\n",
      "107                workingday, -1    0.002692\n",
      "103                 windspeed, -1    0.002664\n",
      "109                      temp, -1    0.002516\n",
      "59                       season_2    0.002503\n",
      "20       casual_quantile_90_month    0.002470\n",
      "42            registered_mean_day    0.002427\n",
      "86                        hour_19    0.002394\n",
      "27   registered_quantile_90_month    0.002367\n",
      "122                     count, -2    0.002324\n",
      "77                        hour_10    0.002308\n",
      "22           registered_std_month    0.002259\n",
      "84                        hour_17    0.002252\n",
      "25   registered_quantile_75_month    0.002193\n",
      "80                        hour_13    0.002027\n",
      "101                      month_11    0.001835\n",
      "76                         hour_9    0.001738\n",
      "120                    casual, -2    0.001653\n",
      "92                        month_2    0.001425\n",
      "100                      month_10    0.001388\n",
      "88                        hour_21    0.001198\n",
      "81                        hour_14    0.001000\n",
      "79                        hour_12    0.000999\n",
      "85                        hour_18    0.000949\n",
      "82                        hour_15    0.000913\n",
      "98                        month_8    0.000896\n",
      "116                   holiday, -2    0.000860\n",
      "1                         holiday    0.000797\n",
      "78                        hour_11    0.000765\n",
      "99                        month_9    0.000759\n",
      "83                        hour_16    0.000628\n",
      "67                    dayofweek_6    0.000000\n",
      "41         casual_quantile_90_day    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "58                      weather_4    0.000000\n",
      "48     registered_quantile_90_day    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "102                      month_12    0.000000\n",
      "97                        month_7    0.000000\n",
      "96                        month_6    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "91                         year_2    0.000000\n",
      "90                        hour_23    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "Fitting positive_casual_pipeline_rf\n",
      "Fitting positive_casual_pipeline_mlp\n",
      "positive_casual_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "8                          casual    0.605710\n",
      "30             count_median_month    0.016511\n",
      "72                         hour_5    0.013941\n",
      "101                      month_11    0.009499\n",
      "71                         hour_4    0.009099\n",
      "36                 casual_std_day    0.008208\n",
      "73                         hour_6    0.008189\n",
      "2                      workingday    0.008053\n",
      "19       casual_quantile_10_month    0.007705\n",
      "74                         hour_7    0.007357\n",
      "53          count_quantile_75_day    0.007305\n",
      "18       casual_quantile_75_month    0.007232\n",
      "69                         hour_2    0.006731\n",
      "51               count_median_day    0.006667\n",
      "10                           hour    0.005775\n",
      "44          registered_median_day    0.005764\n",
      "55          count_quantile_90_day    0.005320\n",
      "75                         hour_8    0.005285\n",
      "95                        month_5    0.005237\n",
      "68                         hour_1    0.005194\n",
      "35                casual_mean_day    0.005158\n",
      "16            casual_median_month    0.005142\n",
      "31        count_quantile_25_month    0.005024\n",
      "23        registered_median_month    0.004990\n",
      "15               casual_std_month    0.004920\n",
      "42            registered_mean_day    0.004880\n",
      "34        count_quantile_90_month    0.004868\n",
      "117                workingday, +2    0.004803\n",
      "17       casual_quantile_25_month    0.004759\n",
      "108                   weather, +1    0.004699\n",
      "118                   weather, +2    0.004619\n",
      "13                      dayofweek    0.004436\n",
      "11                      dayofyear    0.004228\n",
      "24   registered_quantile_25_month    0.004203\n",
      "92                        month_2    0.004128\n",
      "29                count_std_month    0.004058\n",
      "119                      temp, +2    0.003840\n",
      "37              casual_median_day    0.003827\n",
      "6                        humidity    0.003818\n",
      "110                    casual, +1    0.003797\n",
      "50                  count_std_day    0.003797\n",
      "21          registered_mean_month    0.003741\n",
      "25   registered_quantile_75_month    0.003694\n",
      "89                        hour_22    0.003672\n",
      "107                workingday, +1    0.003652\n",
      "14              casual_mean_month    0.003644\n",
      "33        count_quantile_10_month    0.003626\n",
      "87                        hour_20    0.003599\n",
      "70                         hour_3    0.003593\n",
      "5                           atemp    0.003535\n",
      "56                      weather_2    0.003519\n",
      "59                       season_2    0.003463\n",
      "22           registered_std_month    0.003419\n",
      "3                         weather    0.003411\n",
      "103                 windspeed, +1    0.003387\n",
      "28               count_mean_month    0.003303\n",
      "111                registered, +1    0.003303\n",
      "7                       windspeed    0.003275\n",
      "113                 windspeed, +2    0.003265\n",
      "88                        hour_21    0.003260\n",
      "114                     atemp, +2    0.003255\n",
      "4                            temp    0.003144\n",
      "122                     count, +2    0.003133\n",
      "49                 count_mean_day    0.003130\n",
      "109                      temp, +1    0.003082\n",
      "27   registered_quantile_90_month    0.003070\n",
      "96                        month_6    0.003057\n",
      "115                  humidity, +2    0.003050\n",
      "112                     count, +1    0.003044\n",
      "121                registered, +2    0.002970\n",
      "77                        hour_10    0.002967\n",
      "0                          season    0.002886\n",
      "32        count_quantile_75_month    0.002862\n",
      "105                  humidity, +1    0.002814\n",
      "104                     atemp, +1    0.002806\n",
      "20       casual_quantile_90_month    0.002652\n",
      "26   registered_quantile_10_month    0.002617\n",
      "100                      month_10    0.002515\n",
      "98                        month_8    0.002423\n",
      "120                    casual, +2    0.002354\n",
      "57                      weather_3    0.002308\n",
      "93                        month_3    0.002302\n",
      "1                         holiday    0.002048\n",
      "94                        month_4    0.001982\n",
      "99                        month_9    0.001866\n",
      "86                        hour_19    0.001765\n",
      "9                            year    0.001587\n",
      "106                   holiday, +1    0.001544\n",
      "84                        hour_17    0.001417\n",
      "78                        hour_11    0.001340\n",
      "76                         hour_9    0.001310\n",
      "60                       season_3    0.001181\n",
      "80                        hour_13    0.001165\n",
      "79                        hour_12    0.001150\n",
      "81                        hour_14    0.001072\n",
      "85                        hour_18    0.001043\n",
      "83                        hour_16    0.001003\n",
      "82                        hour_15    0.000764\n",
      "116                   holiday, +2    0.000187\n",
      "41         casual_quantile_90_day    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "67                    dayofweek_6    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "97                        month_7    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "48     registered_quantile_90_day    0.000000\n",
      "102                      month_12    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "58                      weather_4    0.000000\n",
      "91                         year_2    0.000000\n",
      "90                        hour_23    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "Fitting pipelines for registered_original\n",
      "Maximum of the target: 886.0\n",
      "Avergae of the target: 155.4472253564468\n",
      "\n",
      "Fitting negative_registered_pipeline_rf\n",
      "Fitting negative_registered_pipeline_mlp\n",
      "negative_registered_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "10                           hour    0.495532\n",
      "112                     count, -1    0.070686\n",
      "8                          casual    0.050302\n",
      "111                registered, -1    0.049279\n",
      "2                      workingday    0.033522\n",
      "71                         hour_4    0.032380\n",
      "36                 casual_std_day    0.028392\n",
      "22           registered_std_month    0.026115\n",
      "26   registered_quantile_10_month    0.016341\n",
      "13                      dayofweek    0.014313\n",
      "21          registered_mean_month    0.013418\n",
      "34        count_quantile_90_month    0.011043\n",
      "28               count_mean_month    0.009384\n",
      "9                            year    0.008057\n",
      "35                casual_mean_day    0.006896\n",
      "27   registered_quantile_90_month    0.006603\n",
      "121                registered, -2    0.006282\n",
      "107                workingday, -1    0.005551\n",
      "72                         hour_5    0.004971\n",
      "120                    casual, -2    0.004836\n",
      "110                    casual, -1    0.004743\n",
      "15               casual_std_month    0.004001\n",
      "122                     count, -2    0.003999\n",
      "29                count_std_month    0.003968\n",
      "24   registered_quantile_25_month    0.003880\n",
      "70                         hour_3    0.003576\n",
      "69                         hour_2    0.003441\n",
      "3                         weather    0.003361\n",
      "55          count_quantile_90_day    0.003274\n",
      "49                 count_mean_day    0.003242\n",
      "42            registered_mean_day    0.002987\n",
      "117                workingday, -2    0.002921\n",
      "11                      dayofyear    0.002792\n",
      "23        registered_median_month    0.002506\n",
      "6                        humidity    0.002504\n",
      "50                  count_std_day    0.002487\n",
      "94                        month_4    0.002441\n",
      "33        count_quantile_10_month    0.002242\n",
      "44          registered_median_day    0.002175\n",
      "51               count_median_day    0.002143\n",
      "0                          season    0.001920\n",
      "14              casual_mean_month    0.001883\n",
      "17       casual_quantile_25_month    0.001827\n",
      "53          count_quantile_75_day    0.001705\n",
      "119                      temp, -2    0.001659\n",
      "4                            temp    0.001656\n",
      "16            casual_median_month    0.001562\n",
      "68                         hour_1    0.001447\n",
      "109                      temp, -1    0.001441\n",
      "73                         hour_6    0.001380\n",
      "93                        month_3    0.001377\n",
      "5                           atemp    0.001376\n",
      "7                       windspeed    0.001370\n",
      "57                      weather_3    0.001329\n",
      "118                   weather, -2    0.001325\n",
      "104                     atemp, -1    0.001297\n",
      "113                 windspeed, -2    0.001287\n",
      "20       casual_quantile_90_month    0.001259\n",
      "99                        month_9    0.001238\n",
      "18       casual_quantile_75_month    0.001210\n",
      "114                     atemp, -2    0.001150\n",
      "19       casual_quantile_10_month    0.001100\n",
      "115                  humidity, -2    0.001099\n",
      "37              casual_median_day    0.001089\n",
      "105                  humidity, -1    0.001076\n",
      "59                       season_2    0.001032\n",
      "103                 windspeed, -1    0.000941\n",
      "60                       season_3    0.000918\n",
      "30             count_median_month    0.000865\n",
      "31        count_quantile_25_month    0.000860\n",
      "56                      weather_2    0.000849\n",
      "25   registered_quantile_75_month    0.000633\n",
      "108                   weather, -1    0.000546\n",
      "106                   holiday, -1    0.000453\n",
      "1                         holiday    0.000365\n",
      "92                        month_2    0.000306\n",
      "32        count_quantile_75_month    0.000287\n",
      "101                      month_11    0.000149\n",
      "95                        month_5    0.000149\n",
      "97                        month_7    0.000000\n",
      "96                        month_6    0.000000\n",
      "41         casual_quantile_90_day    0.000000\n",
      "98                        month_8    0.000000\n",
      "100                      month_10    0.000000\n",
      "102                      month_12    0.000000\n",
      "90                        hour_23    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "116                   holiday, -2    0.000000\n",
      "91                         year_2    0.000000\n",
      "82                        hour_15    0.000000\n",
      "89                        hour_22    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "48     registered_quantile_90_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "58                      weather_4    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "67                    dayofweek_6    0.000000\n",
      "88                        hour_21    0.000000\n",
      "74                         hour_7    0.000000\n",
      "75                         hour_8    0.000000\n",
      "76                         hour_9    0.000000\n",
      "77                        hour_10    0.000000\n",
      "78                        hour_11    0.000000\n",
      "79                        hour_12    0.000000\n",
      "80                        hour_13    0.000000\n",
      "81                        hour_14    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "83                        hour_16    0.000000\n",
      "84                        hour_17    0.000000\n",
      "85                        hour_18    0.000000\n",
      "86                        hour_19    0.000000\n",
      "87                        hour_20    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "Fitting positive_registered_pipeline_rf\n",
      "Fitting positive_registered_pipeline_mlp\n",
      "positive_registered_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "112                     count, +1    0.471042\n",
      "10                           hour    0.080891\n",
      "111                registered, +1    0.071294\n",
      "8                          casual    0.069241\n",
      "71                         hour_4    0.027460\n",
      "2                      workingday    0.020199\n",
      "27   registered_quantile_90_month    0.019891\n",
      "28               count_mean_month    0.017724\n",
      "9                            year    0.014880\n",
      "24   registered_quantile_25_month    0.014682\n",
      "26   registered_quantile_10_month    0.011308\n",
      "44          registered_median_day    0.010725\n",
      "19       casual_quantile_10_month    0.009681\n",
      "93                        month_3    0.008781\n",
      "70                         hour_3    0.007483\n",
      "50                  count_std_day    0.007068\n",
      "21          registered_mean_month    0.006592\n",
      "13                      dayofweek    0.006170\n",
      "121                registered, +2    0.006093\n",
      "36                 casual_std_day    0.006063\n",
      "120                    casual, +2    0.005320\n",
      "55          count_quantile_90_day    0.005148\n",
      "122                     count, +2    0.004563\n",
      "29                count_std_month    0.004179\n",
      "34        count_quantile_90_month    0.004150\n",
      "42            registered_mean_day    0.003492\n",
      "3                         weather    0.003470\n",
      "22           registered_std_month    0.003451\n",
      "25   registered_quantile_75_month    0.003317\n",
      "110                    casual, +1    0.003139\n",
      "6                        humidity    0.003121\n",
      "11                      dayofyear    0.003043\n",
      "99                        month_9    0.002950\n",
      "23        registered_median_month    0.002722\n",
      "53          count_quantile_75_day    0.002679\n",
      "49                 count_mean_day    0.002638\n",
      "107                workingday, +1    0.002400\n",
      "20       casual_quantile_90_month    0.002044\n",
      "51               count_median_day    0.001998\n",
      "33        count_quantile_10_month    0.001992\n",
      "5                           atemp    0.001830\n",
      "15               casual_std_month    0.001818\n",
      "4                            temp    0.001737\n",
      "17       casual_quantile_25_month    0.001736\n",
      "14              casual_mean_month    0.001702\n",
      "108                   weather, +1    0.001686\n",
      "35                casual_mean_day    0.001669\n",
      "101                      month_11    0.001658\n",
      "114                     atemp, +2    0.001658\n",
      "73                         hour_6    0.001615\n",
      "94                        month_4    0.001551\n",
      "116                   holiday, +2    0.001518\n",
      "118                   weather, +2    0.001471\n",
      "57                      weather_3    0.001432\n",
      "69                         hour_2    0.001419\n",
      "16            casual_median_month    0.001377\n",
      "92                        month_2    0.001363\n",
      "56                      weather_2    0.001339\n",
      "109                      temp, +1    0.001337\n",
      "103                 windspeed, +1    0.001334\n",
      "7                       windspeed    0.001325\n",
      "113                 windspeed, +2    0.001219\n",
      "115                  humidity, +2    0.001199\n",
      "105                  humidity, +1    0.001192\n",
      "104                     atemp, +1    0.001176\n",
      "30             count_median_month    0.001169\n",
      "72                         hour_5    0.001149\n",
      "119                      temp, +2    0.000880\n",
      "106                   holiday, +1    0.000836\n",
      "37              casual_median_day    0.000816\n",
      "117                workingday, +2    0.000791\n",
      "31        count_quantile_25_month    0.000714\n",
      "95                        month_5    0.000544\n",
      "59                       season_2    0.000537\n",
      "68                         hour_1    0.000507\n",
      "18       casual_quantile_75_month    0.000423\n",
      "1                         holiday    0.000366\n",
      "60                       season_3    0.000292\n",
      "100                      month_10    0.000273\n",
      "98                        month_8    0.000253\n",
      "96                        month_6    0.000000\n",
      "97                        month_7    0.000000\n",
      "88                        hour_21    0.000000\n",
      "102                      month_12    0.000000\n",
      "91                         year_2    0.000000\n",
      "90                        hour_23    0.000000\n",
      "89                        hour_22    0.000000\n",
      "0                          season    0.000000\n",
      "87                        hour_20    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "58                      weather_4    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "48     registered_quantile_90_day    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "41         casual_quantile_90_day    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "32        count_quantile_75_month    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "86                        hour_19    0.000000\n",
      "79                        hour_12    0.000000\n",
      "85                        hour_18    0.000000\n",
      "84                        hour_17    0.000000\n",
      "83                        hour_16    0.000000\n",
      "82                        hour_15    0.000000\n",
      "81                        hour_14    0.000000\n",
      "80                        hour_13    0.000000\n",
      "78                        hour_11    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "77                        hour_10    0.000000\n",
      "76                         hour_9    0.000000\n",
      "75                         hour_8    0.000000\n",
      "74                         hour_7    0.000000\n",
      "67                    dayofweek_6    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "Fitting pipelines for count_original\n",
      "Maximum of the target: 977.0\n",
      "Avergae of the target: 191.47112524361472\n",
      "\n",
      "Fitting negative_count_pipeline_rf\n",
      "Fitting negative_count_pipeline_mlp\n",
      "negative_count_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "10                           hour    0.558980\n",
      "8                          casual    0.090738\n",
      "111                registered, -1    0.049042\n",
      "112                     count, -1    0.046626\n",
      "28               count_mean_month    0.030248\n",
      "2                      workingday    0.029688\n",
      "36                 casual_std_day    0.022088\n",
      "71                         hour_4    0.014115\n",
      "24   registered_quantile_25_month    0.009100\n",
      "22           registered_std_month    0.008997\n",
      "26   registered_quantile_10_month    0.006790\n",
      "120                    casual, -2    0.006537\n",
      "121                registered, -2    0.005884\n",
      "13                      dayofweek    0.005780\n",
      "27   registered_quantile_90_month    0.005213\n",
      "110                    casual, -1    0.005197\n",
      "72                         hour_5    0.005075\n",
      "21          registered_mean_month    0.005014\n",
      "29                count_std_month    0.004462\n",
      "34        count_quantile_90_month    0.004147\n",
      "9                            year    0.003938\n",
      "49                 count_mean_day    0.003723\n",
      "70                         hour_3    0.003717\n",
      "94                        month_4    0.003650\n",
      "122                     count, -2    0.003236\n",
      "3                         weather    0.002991\n",
      "6                        humidity    0.002782\n",
      "5                           atemp    0.002669\n",
      "117                workingday, -2    0.002660\n",
      "99                        month_9    0.002453\n",
      "11                      dayofyear    0.002293\n",
      "51               count_median_day    0.002198\n",
      "57                      weather_3    0.002128\n",
      "23        registered_median_month    0.002051\n",
      "93                        month_3    0.002000\n",
      "15               casual_std_month    0.001981\n",
      "19       casual_quantile_10_month    0.001738\n",
      "35                casual_mean_day    0.001664\n",
      "37              casual_median_day    0.001631\n",
      "107                workingday, -1    0.001562\n",
      "50                  count_std_day    0.001552\n",
      "31        count_quantile_25_month    0.001491\n",
      "17       casual_quantile_25_month    0.001489\n",
      "44          registered_median_day    0.001460\n",
      "55          count_quantile_90_day    0.001422\n",
      "53          count_quantile_75_day    0.001386\n",
      "119                      temp, -2    0.001372\n",
      "20       casual_quantile_90_month    0.001336\n",
      "106                   holiday, -1    0.001288\n",
      "109                      temp, -1    0.001282\n",
      "25   registered_quantile_75_month    0.001211\n",
      "14              casual_mean_month    0.001166\n",
      "104                     atemp, -1    0.001060\n",
      "4                            temp    0.001037\n",
      "56                      weather_2    0.001004\n",
      "60                       season_3    0.000997\n",
      "69                         hour_2    0.000994\n",
      "114                     atemp, -2    0.000946\n",
      "105                  humidity, -1    0.000944\n",
      "115                  humidity, -2    0.000925\n",
      "113                 windspeed, -2    0.000918\n",
      "73                         hour_6    0.000910\n",
      "68                         hour_1    0.000842\n",
      "7                       windspeed    0.000825\n",
      "118                   weather, -2    0.000787\n",
      "103                 windspeed, -1    0.000741\n",
      "33        count_quantile_10_month    0.000681\n",
      "59                       season_2    0.000681\n",
      "16            casual_median_month    0.000624\n",
      "108                   weather, -1    0.000532\n",
      "1                         holiday    0.000489\n",
      "96                        month_6    0.000479\n",
      "42            registered_mean_day    0.000459\n",
      "18       casual_quantile_75_month    0.000413\n",
      "116                   holiday, -2    0.000266\n",
      "101                      month_11    0.000235\n",
      "0                          season    0.000224\n",
      "30             count_median_month    0.000220\n",
      "92                        month_2    0.000201\n",
      "100                      month_10    0.000172\n",
      "95                        month_5    0.000161\n",
      "48     registered_quantile_90_day    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "58                      weather_4    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "41         casual_quantile_90_day    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "32        count_quantile_75_month    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "102                      month_12    0.000000\n",
      "77                        hour_10    0.000000\n",
      "78                        hour_11    0.000000\n",
      "87                        hour_20    0.000000\n",
      "79                        hour_12    0.000000\n",
      "80                        hour_13    0.000000\n",
      "81                        hour_14    0.000000\n",
      "82                        hour_15    0.000000\n",
      "83                        hour_16    0.000000\n",
      "84                        hour_17    0.000000\n",
      "85                        hour_18    0.000000\n",
      "86                        hour_19    0.000000\n",
      "88                        hour_21    0.000000\n",
      "67                    dayofweek_6    0.000000\n",
      "89                        hour_22    0.000000\n",
      "90                        hour_23    0.000000\n",
      "91                         year_2    0.000000\n",
      "76                         hour_9    0.000000\n",
      "75                         hour_8    0.000000\n",
      "74                         hour_7    0.000000\n",
      "97                        month_7    0.000000\n",
      "98                        month_8    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "Fitting positive_count_pipeline_rf\n",
      "Fitting positive_count_pipeline_mlp\n",
      "positive_count_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "112                     count, +1    0.562667\n",
      "8                          casual    0.103824\n",
      "10                           hour    0.054849\n",
      "28               count_mean_month    0.018319\n",
      "71                         hour_4    0.013181\n",
      "111                registered, +1    0.013062\n",
      "27   registered_quantile_90_month    0.012667\n",
      "9                            year    0.012391\n",
      "25   registered_quantile_75_month    0.012235\n",
      "2                      workingday    0.010018\n",
      "120                    casual, +2    0.009650\n",
      "21          registered_mean_month    0.007749\n",
      "13                      dayofweek    0.007559\n",
      "34        count_quantile_90_month    0.007460\n",
      "26   registered_quantile_10_month    0.006626\n",
      "93                        month_3    0.006613\n",
      "70                         hour_3    0.006113\n",
      "98                        month_8    0.005844\n",
      "53          count_quantile_75_day    0.005736\n",
      "50                  count_std_day    0.005545\n",
      "121                registered, +2    0.005217\n",
      "72                         hour_5    0.005204\n",
      "33        count_quantile_10_month    0.005191\n",
      "110                    casual, +1    0.005016\n",
      "122                     count, +2    0.004477\n",
      "35                casual_mean_day    0.004243\n",
      "24   registered_quantile_25_month    0.003831\n",
      "6                        humidity    0.003820\n",
      "44          registered_median_day    0.003663\n",
      "16            casual_median_month    0.003609\n",
      "36                 casual_std_day    0.003055\n",
      "4                            temp    0.002931\n",
      "117                workingday, +2    0.002924\n",
      "20       casual_quantile_90_month    0.002869\n",
      "22           registered_std_month    0.002745\n",
      "49                 count_mean_day    0.002684\n",
      "15               casual_std_month    0.002684\n",
      "5                           atemp    0.002440\n",
      "42            registered_mean_day    0.002406\n",
      "55          count_quantile_90_day    0.002374\n",
      "11                      dayofyear    0.002342\n",
      "109                      temp, +1    0.002175\n",
      "14              casual_mean_month    0.002166\n",
      "31        count_quantile_25_month    0.002095\n",
      "23        registered_median_month    0.002083\n",
      "94                        month_4    0.002078\n",
      "108                   weather, +1    0.002002\n",
      "29                count_std_month    0.001965\n",
      "57                      weather_3    0.001788\n",
      "104                     atemp, +1    0.001627\n",
      "3                         weather    0.001615\n",
      "17       casual_quantile_25_month    0.001563\n",
      "51               count_median_day    0.001390\n",
      "119                      temp, +2    0.001351\n",
      "105                  humidity, +1    0.001337\n",
      "114                     atemp, +2    0.001308\n",
      "107                workingday, +1    0.001235\n",
      "69                         hour_2    0.001088\n",
      "103                 windspeed, +1    0.001074\n",
      "68                         hour_1    0.001069\n",
      "7                       windspeed    0.001044\n",
      "113                 windspeed, +2    0.001014\n",
      "118                   weather, +2    0.000954\n",
      "32        count_quantile_75_month    0.000910\n",
      "99                        month_9    0.000878\n",
      "73                         hour_6    0.000874\n",
      "18       casual_quantile_75_month    0.000858\n",
      "115                  humidity, +2    0.000858\n",
      "100                      month_10    0.000684\n",
      "92                        month_2    0.000621\n",
      "59                       season_2    0.000621\n",
      "116                   holiday, +2    0.000586\n",
      "19       casual_quantile_10_month    0.000548\n",
      "101                      month_11    0.000483\n",
      "56                      weather_2    0.000477\n",
      "37              casual_median_day    0.000460\n",
      "106                   holiday, +1    0.000448\n",
      "60                       season_3    0.000378\n",
      "30             count_median_month    0.000304\n",
      "1                         holiday    0.000157\n",
      "102                      month_12    0.000000\n",
      "97                        month_7    0.000000\n",
      "96                        month_6    0.000000\n",
      "95                        month_5    0.000000\n",
      "88                        hour_21    0.000000\n",
      "91                         year_2    0.000000\n",
      "90                        hour_23    0.000000\n",
      "89                        hour_22    0.000000\n",
      "0                          season    0.000000\n",
      "87                        hour_20    0.000000\n",
      "46     registered_quantile_75_day    0.000000\n",
      "62                    dayofweek_1    0.000000\n",
      "58                      weather_4    0.000000\n",
      "54          count_quantile_10_day    0.000000\n",
      "52          count_quantile_25_day    0.000000\n",
      "48     registered_quantile_90_day    0.000000\n",
      "47     registered_quantile_10_day    0.000000\n",
      "45     registered_quantile_25_day    0.000000\n",
      "86                        hour_19    0.000000\n",
      "43             registered_std_day    0.000000\n",
      "41         casual_quantile_90_day    0.000000\n",
      "40         casual_quantile_10_day    0.000000\n",
      "39         casual_quantile_75_day    0.000000\n",
      "38         casual_quantile_25_day    0.000000\n",
      "12                     weekofyear    0.000000\n",
      "63                    dayofweek_2    0.000000\n",
      "64                    dayofweek_3    0.000000\n",
      "65                    dayofweek_4    0.000000\n",
      "66                    dayofweek_5    0.000000\n",
      "67                    dayofweek_6    0.000000\n",
      "74                         hour_7    0.000000\n",
      "75                         hour_8    0.000000\n",
      "76                         hour_9    0.000000\n",
      "77                        hour_10    0.000000\n",
      "78                        hour_11    0.000000\n",
      "79                        hour_12    0.000000\n",
      "80                        hour_13    0.000000\n",
      "81                        hour_14    0.000000\n",
      "82                        hour_15    0.000000\n",
      "83                        hour_16    0.000000\n",
      "84                        hour_17    0.000000\n",
      "85                        hour_18    0.000000\n",
      "61                       season_4    0.000000\n",
      "\n",
      "\n",
      "Predicting pipelines...\n",
      "\n",
      "Merging predictions...\n",
      "Merging predictions for negative_casual\n",
      "Merging predictions for positive_casual\n",
      "Maximum of the target prediction:  312.47217534183676\n",
      "Average of the target prediction:  36.6219846497041\n",
      "\n",
      "Merging predictions for negative_registered\n",
      "Merging predictions for positive_registered\n",
      "Maximum of the target prediction:  909.0956444182528\n",
      "Average of the target prediction:  163.51073028604387\n",
      "\n",
      "Merging predictions for negative_count\n",
      "Merging predictions for positive_count\n",
      "Maximum of the target prediction:  1090.2268412603992\n",
      "Average of the target prediction:  200.1807453720699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_not_to_use = ['datetime', 'dataset', 'day', 'month']\n",
    "smoothed_columns = ['registered', 'count']\n",
    "original_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "\n",
    "columns_not_to_use = columns_not_to_use + smoothed_columns + original_columns\n",
    "\n",
    "directions = ['negative', 'positive']\n",
    "rf = [True, True, True]\n",
    "mlp = [True, True, True]\n",
    "trees = [n, n, n]\n",
    "max_iter = 2000\n",
    "hidden_layer_sizes = [(150, 150, 150), (250, 250, 250, 250), (200, 200, 200)]\n",
    "max_iter_no_change = [10, 15, 10]\n",
    "\n",
    "data_sample = training_data['positive']['X'].copy()\n",
    "data_sample = data_sample.drop(columns = columns_not_to_use, axis=1)\n",
    "\n",
    "# shuffle the data\n",
    "data_sample = data_sample.sample(frac=1, random_state=0)\n",
    "data_sample = data_sample[:2000]\n",
    "categorical_features = np.zeros((len(data_sample.columns),), dtype=bool)\n",
    "\n",
    "for col in data_sample.columns:\n",
    "    # check weather only 0 and 1 are present in the column\n",
    "    if len(data_sample[col].unique()) == 2:\n",
    "        # if so, append the column to the list of categorical features\n",
    "        categorical_features[data_sample.columns.get_loc(col)] = True\n",
    "\n",
    "\n",
    "train_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "test_columns = train_columns\n",
    "\n",
    "\n",
    "# create the pipelines\n",
    "pipelines = create_pipelines(train_columns, directions, \n",
    "                             trees, hidden_layer_sizes,\n",
    "                             max_iter_no_change, categorical_features,\n",
    "                             rf=rf, mlp=mlp, max_iter=max_iter)\n",
    "\n",
    "# fit the pipelines\n",
    "fitted_pipelines = fit_pipelines(pipelines, training_data_registered, \n",
    "                                 train_columns, columns_not_to_use,\n",
    "                                 directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# predict the pipelines\n",
    "predictions, dataframes = predict_pipelines(fitted_pipelines, training_data_registered, \n",
    "                                            train_columns, test_columns, \n",
    "                                            columns_not_to_use, test_period, \n",
    "                                            maximum_day, directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# evaluate the pipelines\n",
    "triaining_data_count = merge_predictions(predictions, training_data_registered, test_columns, directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the predictions for count from the training data\n",
    "count_predictions = triaining_data_count['positive']['y']['count']\n",
    "\n",
    "# save the predictions into a csv file with the datetime column\n",
    "count_predictions = pd.concat([triaining_data_count['positive']['y']['datetime'], count_predictions], axis=1)\n",
    "\n",
    "# set negative values to zero\n",
    "count_predictions.loc[count_predictions['count'] < 0, 'count'] = 0\n",
    "\n",
    "count_predictions.to_csv('../../data/processed/count_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting pipelines for casual_original\n",
      "Maximum of the target: 367.0\n",
      "Avergae of the target: 36.023899887167914\n",
      "\n",
      "Fitting negative_casual_pipeline_rf\n",
      "Fitting negative_casual_pipeline_mlp\n",
      "negative_casual_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "8                          casual    0.576487\n",
      "74                         hour_5    0.015731\n",
      "15                      dayofweek    0.014037\n",
      "32             count_median_month    0.013357\n",
      "75                         hour_6    0.012955\n",
      "53               count_median_day    0.011814\n",
      "38                 casual_std_day    0.011554\n",
      "46          registered_median_day    0.011322\n",
      "36        count_quantile_90_month    0.010878\n",
      "17               casual_std_month    0.008726\n",
      "73                         hour_4    0.008025\n",
      "119                workingday, -2    0.006958\n",
      "19       casual_quantile_25_month    0.006702\n",
      "77                         hour_8    0.006689\n",
      "57          count_quantile_90_day    0.006493\n",
      "97                        month_5    0.006373\n",
      "12                           hour    0.006334\n",
      "2                      workingday    0.006316\n",
      "11                          month    0.006067\n",
      "95                        month_3    0.005755\n",
      "31                count_std_month    0.005597\n",
      "20       casual_quantile_75_month    0.005582\n",
      "71                         hour_2    0.005566\n",
      "33        count_quantile_25_month    0.005475\n",
      "103                      month_11    0.005385\n",
      "25        registered_median_month    0.005295\n",
      "39              casual_median_day    0.005263\n",
      "37                casual_mean_day    0.005202\n",
      "76                         hour_7    0.004978\n",
      "18            casual_median_month    0.004954\n",
      "13                      dayofyear    0.004901\n",
      "89                        hour_20    0.004861\n",
      "62                       season_3    0.004773\n",
      "72                         hour_3    0.004685\n",
      "16              casual_mean_month    0.004575\n",
      "101                       month_9    0.004359\n",
      "35        count_quantile_10_month    0.004215\n",
      "10                           year    0.004162\n",
      "52                  count_std_day    0.004076\n",
      "112                    casual, -1    0.004035\n",
      "21       casual_quantile_10_month    0.004029\n",
      "44            registered_mean_day    0.004004\n",
      "28   registered_quantile_10_month    0.003989\n",
      "26   registered_quantile_25_month    0.003826\n",
      "27   registered_quantile_75_month    0.003823\n",
      "61                       season_2    0.003703\n",
      "34        count_quantile_75_month    0.003693\n",
      "23          registered_mean_month    0.003655\n",
      "5                           atemp    0.003622\n",
      "22       casual_quantile_90_month    0.003622\n",
      "120                   weather, -2    0.003537\n",
      "59                      weather_3    0.003423\n",
      "107                  humidity, -1    0.003303\n",
      "108                   holiday, -1    0.003274\n",
      "86                        hour_17    0.003255\n",
      "51                 count_mean_day    0.003226\n",
      "115                 windspeed, -2    0.003222\n",
      "3                         weather    0.003051\n",
      "94                        month_2    0.003010\n",
      "9                      registered    0.002992\n",
      "6                        humidity    0.002974\n",
      "123                registered, -2    0.002955\n",
      "91                        hour_22    0.002925\n",
      "4                            temp    0.002924\n",
      "113                registered, -1    0.002918\n",
      "114                     count, -1    0.002891\n",
      "79                        hour_10    0.002860\n",
      "7                       windspeed    0.002724\n",
      "105                 windspeed, -1    0.002687\n",
      "55          count_quantile_75_day    0.002674\n",
      "117                  humidity, -2    0.002572\n",
      "121                      temp, -2    0.002556\n",
      "111                      temp, -1    0.002500\n",
      "116                     atemp, -2    0.002477\n",
      "70                         hour_1    0.002369\n",
      "90                        hour_21    0.002355\n",
      "106                     atemp, -1    0.002343\n",
      "29   registered_quantile_90_month    0.002287\n",
      "58                      weather_2    0.002281\n",
      "100                       month_8    0.002272\n",
      "124                     count, -2    0.002263\n",
      "110                   weather, -1    0.002233\n",
      "96                        month_4    0.002204\n",
      "122                    casual, -2    0.001928\n",
      "0                          season    0.001837\n",
      "102                      month_10    0.001753\n",
      "109                workingday, -1    0.001728\n",
      "78                         hour_9    0.001717\n",
      "24           registered_std_month    0.001626\n",
      "82                        hour_13    0.001450\n",
      "84                        hour_15    0.001090\n",
      "83                        hour_14    0.001027\n",
      "87                        hour_18    0.000945\n",
      "80                        hour_11    0.000924\n",
      "88                        hour_19    0.000902\n",
      "81                        hour_12    0.000876\n",
      "85                        hour_16    0.000819\n",
      "1                         holiday    0.000717\n",
      "118                   holiday, -2    0.000645\n",
      "49     registered_quantile_10_day    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "30               count_mean_month    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "42         casual_quantile_10_day    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "45             registered_std_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "92                        hour_23    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "60                      weather_4    0.000000\n",
      "104                      month_12    0.000000\n",
      "93                         year_2    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "63                       season_4    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "99                        month_7    0.000000\n",
      "98                        month_6    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "\n",
      "Fitting positive_casual_pipeline_rf\n",
      "Fitting positive_casual_pipeline_mlp\n",
      "positive_casual_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "8                          casual    0.558822\n",
      "61                       season_2    0.017604\n",
      "46          registered_median_day    0.016252\n",
      "38                 casual_std_day    0.013871\n",
      "74                         hour_5    0.013137\n",
      "39              casual_median_day    0.010752\n",
      "53               count_median_day    0.010463\n",
      "15                      dayofweek    0.009855\n",
      "75                         hour_6    0.009516\n",
      "77                         hour_8    0.008703\n",
      "2                      workingday    0.008303\n",
      "71                         hour_2    0.007897\n",
      "76                         hour_7    0.007856\n",
      "73                         hour_4    0.007429\n",
      "21       casual_quantile_10_month    0.007202\n",
      "103                      month_11    0.006810\n",
      "26   registered_quantile_25_month    0.006476\n",
      "31                count_std_month    0.006346\n",
      "55          count_quantile_75_day    0.006156\n",
      "110                   weather, +1    0.006077\n",
      "37                casual_mean_day    0.005999\n",
      "30               count_mean_month    0.005816\n",
      "57          count_quantile_90_day    0.005742\n",
      "19       casual_quantile_25_month    0.005690\n",
      "25        registered_median_month    0.005574\n",
      "17               casual_std_month    0.005313\n",
      "11                          month    0.005238\n",
      "12                           hour    0.005184\n",
      "27   registered_quantile_75_month    0.005179\n",
      "32             count_median_month    0.005054\n",
      "10                           year    0.004996\n",
      "33        count_quantile_25_month    0.004938\n",
      "100                       month_8    0.004772\n",
      "13                      dayofyear    0.004698\n",
      "16              casual_mean_month    0.004692\n",
      "20       casual_quantile_75_month    0.004548\n",
      "97                        month_5    0.004361\n",
      "36        count_quantile_90_month    0.004280\n",
      "91                        hour_22    0.004264\n",
      "51                 count_mean_day    0.004151\n",
      "24           registered_std_month    0.004114\n",
      "52                  count_std_day    0.004069\n",
      "72                         hour_3    0.003957\n",
      "112                    casual, +1    0.003927\n",
      "22       casual_quantile_90_month    0.003843\n",
      "94                        month_2    0.003805\n",
      "3                         weather    0.003681\n",
      "5                           atemp    0.003653\n",
      "34        count_quantile_75_month    0.003644\n",
      "118                   holiday, +2    0.003618\n",
      "79                        hour_10    0.003554\n",
      "121                      temp, +2    0.003541\n",
      "119                workingday, +2    0.003525\n",
      "18            casual_median_month    0.003456\n",
      "58                      weather_2    0.003432\n",
      "113                registered, +1    0.003356\n",
      "7                       windspeed    0.003319\n",
      "106                     atemp, +1    0.003259\n",
      "95                        month_3    0.003257\n",
      "9                      registered    0.003243\n",
      "114                     count, +1    0.003183\n",
      "44            registered_mean_day    0.003163\n",
      "105                 windspeed, +1    0.003162\n",
      "120                   weather, +2    0.003118\n",
      "6                        humidity    0.003081\n",
      "116                     atemp, +2    0.003073\n",
      "124                     count, +2    0.003059\n",
      "96                        month_4    0.003025\n",
      "123                registered, +2    0.003004\n",
      "107                  humidity, +1    0.002938\n",
      "109                workingday, +1    0.002911\n",
      "23          registered_mean_month    0.002862\n",
      "115                 windspeed, +2    0.002846\n",
      "111                      temp, +1    0.002831\n",
      "117                  humidity, +2    0.002728\n",
      "98                        month_6    0.002671\n",
      "86                        hour_17    0.002590\n",
      "28   registered_quantile_10_month    0.002535\n",
      "4                            temp    0.002529\n",
      "90                        hour_21    0.002489\n",
      "89                        hour_20    0.002413\n",
      "70                         hour_1    0.002390\n",
      "122                    casual, +2    0.002368\n",
      "101                       month_9    0.002002\n",
      "82                        hour_13    0.001912\n",
      "29   registered_quantile_90_month    0.001763\n",
      "1                         holiday    0.001692\n",
      "35        count_quantile_10_month    0.001679\n",
      "83                        hour_14    0.001644\n",
      "87                        hour_18    0.001541\n",
      "80                        hour_11    0.001378\n",
      "78                         hour_9    0.001375\n",
      "102                      month_10    0.001374\n",
      "0                          season    0.001341\n",
      "81                        hour_12    0.001001\n",
      "59                      weather_3    0.000978\n",
      "108                   holiday, +1    0.000958\n",
      "88                        hour_19    0.000866\n",
      "84                        hour_15    0.000766\n",
      "85                        hour_16    0.000496\n",
      "45             registered_std_day    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "49     registered_quantile_10_day    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "93                         year_2    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "42         casual_quantile_10_day    0.000000\n",
      "63                       season_4    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "60                      weather_4    0.000000\n",
      "92                        hour_23    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "104                      month_12    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "99                        month_7    0.000000\n",
      "62                       season_3    0.000000\n",
      "\n",
      "Fitting pipelines for registered_original\n",
      "Maximum of the target: 886.0\n",
      "Avergae of the target: 155.4472253564468\n",
      "\n",
      "Fitting negative_registered_pipeline_rf\n",
      "Fitting negative_registered_pipeline_mlp\n",
      "negative_registered_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "9                      registered    0.776140\n",
      "73                         hour_4    0.024391\n",
      "24           registered_std_month    0.011586\n",
      "12                           hour    0.010922\n",
      "8                          casual    0.010551\n",
      "114                     count, -1    0.010142\n",
      "112                    casual, -1    0.008959\n",
      "113                registered, -1    0.008649\n",
      "123                registered, -2    0.007237\n",
      "122                    casual, -2    0.006749\n",
      "74                         hour_5    0.005035\n",
      "23          registered_mean_month    0.004767\n",
      "36        count_quantile_90_month    0.004742\n",
      "10                           year    0.004354\n",
      "124                     count, -2    0.004139\n",
      "2                      workingday    0.003828\n",
      "11                          month    0.003728\n",
      "53               count_median_day    0.003647\n",
      "29   registered_quantile_90_month    0.003458\n",
      "46          registered_median_day    0.003398\n",
      "62                       season_3    0.003392\n",
      "33        count_quantile_25_month    0.003254\n",
      "28   registered_quantile_10_month    0.003231\n",
      "13                      dayofyear    0.003025\n",
      "3                         weather    0.002561\n",
      "52                  count_std_day    0.002495\n",
      "6                        humidity    0.002388\n",
      "37                casual_mean_day    0.002312\n",
      "30               count_mean_month    0.002249\n",
      "26   registered_quantile_25_month    0.002242\n",
      "38                 casual_std_day    0.002101\n",
      "15                      dayofweek    0.002014\n",
      "75                         hour_6    0.001959\n",
      "39              casual_median_day    0.001892\n",
      "31                count_std_month    0.001890\n",
      "27   registered_quantile_75_month    0.001884\n",
      "96                        month_4    0.001869\n",
      "25        registered_median_month    0.001851\n",
      "109                workingday, -1    0.001833\n",
      "72                         hour_3    0.001752\n",
      "95                        month_3    0.001663\n",
      "110                   weather, -1    0.001637\n",
      "22       casual_quantile_90_month    0.001633\n",
      "111                      temp, -1    0.001527\n",
      "106                     atemp, -1    0.001429\n",
      "21       casual_quantile_10_month    0.001395\n",
      "5                           atemp    0.001389\n",
      "7                       windspeed    0.001315\n",
      "105                 windspeed, -1    0.001301\n",
      "121                      temp, -2    0.001297\n",
      "18            casual_median_month    0.001287\n",
      "16              casual_mean_month    0.001274\n",
      "19       casual_quantile_25_month    0.001265\n",
      "34        count_quantile_75_month    0.001241\n",
      "107                  humidity, -1    0.001203\n",
      "58                      weather_2    0.001192\n",
      "116                     atemp, -2    0.001098\n",
      "4                            temp    0.001060\n",
      "117                  humidity, -2    0.001046\n",
      "55          count_quantile_75_day    0.001024\n",
      "115                 windspeed, -2    0.001001\n",
      "17               casual_std_month    0.000870\n",
      "71                         hour_2    0.000782\n",
      "51                 count_mean_day    0.000776\n",
      "120                   weather, -2    0.000755\n",
      "101                       month_9    0.000704\n",
      "35        count_quantile_10_month    0.000700\n",
      "20       casual_quantile_75_month    0.000656\n",
      "59                      weather_3    0.000633\n",
      "1                         holiday    0.000554\n",
      "119                workingday, -2    0.000533\n",
      "70                         hour_1    0.000527\n",
      "61                       season_2    0.000503\n",
      "44            registered_mean_day    0.000496\n",
      "108                   holiday, -1    0.000355\n",
      "32             count_median_month    0.000309\n",
      "0                          season    0.000284\n",
      "97                        month_5    0.000236\n",
      "57          count_quantile_90_day    0.000202\n",
      "100                       month_8    0.000151\n",
      "98                        month_6    0.000086\n",
      "77                         hour_8    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "63                       season_4    0.000000\n",
      "60                      weather_4    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "103                      month_11    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "49     registered_quantile_10_day    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "118                   holiday, -2    0.000000\n",
      "45             registered_std_day    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "42         casual_quantile_10_day    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "104                      month_12    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "102                      month_10    0.000000\n",
      "78                         hour_9    0.000000\n",
      "79                        hour_10    0.000000\n",
      "80                        hour_11    0.000000\n",
      "81                        hour_12    0.000000\n",
      "82                        hour_13    0.000000\n",
      "83                        hour_14    0.000000\n",
      "84                        hour_15    0.000000\n",
      "85                        hour_16    0.000000\n",
      "86                        hour_17    0.000000\n",
      "87                        hour_18    0.000000\n",
      "88                        hour_19    0.000000\n",
      "89                        hour_20    0.000000\n",
      "90                        hour_21    0.000000\n",
      "91                        hour_22    0.000000\n",
      "92                        hour_23    0.000000\n",
      "93                         year_2    0.000000\n",
      "94                        month_2    0.000000\n",
      "76                         hour_7    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "99                        month_7    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "\n",
      "Fitting positive_registered_pipeline_rf\n",
      "Fitting positive_registered_pipeline_mlp\n",
      "positive_registered_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "9                      registered    0.783798\n",
      "73                         hour_4    0.030401\n",
      "8                          casual    0.014224\n",
      "12                           hour    0.009935\n",
      "114                     count, +1    0.008493\n",
      "122                    casual, +2    0.008018\n",
      "113                registered, +1    0.007481\n",
      "112                    casual, +1    0.006714\n",
      "38                 casual_std_day    0.006680\n",
      "2                      workingday    0.005116\n",
      "37                casual_mean_day    0.004326\n",
      "95                        month_3    0.004065\n",
      "29   registered_quantile_90_month    0.003815\n",
      "94                        month_2    0.003596\n",
      "123                registered, +2    0.003567\n",
      "55          count_quantile_75_day    0.003523\n",
      "75                         hour_6    0.003497\n",
      "74                         hour_5    0.003409\n",
      "28   registered_quantile_10_month    0.003194\n",
      "33        count_quantile_25_month    0.003185\n",
      "10                           year    0.003066\n",
      "23          registered_mean_month    0.002952\n",
      "25        registered_median_month    0.002760\n",
      "124                     count, +2    0.002759\n",
      "35        count_quantile_10_month    0.002695\n",
      "36        count_quantile_90_month    0.002669\n",
      "31                count_std_month    0.002459\n",
      "15                      dayofweek    0.002420\n",
      "100                       month_8    0.002408\n",
      "27   registered_quantile_75_month    0.002382\n",
      "13                      dayofyear    0.002358\n",
      "57          count_quantile_90_day    0.001909\n",
      "46          registered_median_day    0.001904\n",
      "11                          month    0.001734\n",
      "58                      weather_2    0.001676\n",
      "39              casual_median_day    0.001606\n",
      "71                         hour_2    0.001591\n",
      "108                   holiday, +1    0.001559\n",
      "6                        humidity    0.001545\n",
      "17               casual_std_month    0.001542\n",
      "4                            temp    0.001486\n",
      "26   registered_quantile_25_month    0.001446\n",
      "72                         hour_3    0.001377\n",
      "120                   weather, +2    0.001358\n",
      "109                workingday, +1    0.001349\n",
      "16              casual_mean_month    0.001343\n",
      "101                       month_9    0.001317\n",
      "61                       season_2    0.001308\n",
      "5                           atemp    0.001155\n",
      "18            casual_median_month    0.001126\n",
      "106                     atemp, +1    0.001109\n",
      "21       casual_quantile_10_month    0.001093\n",
      "0                          season    0.001092\n",
      "115                 windspeed, +2    0.001083\n",
      "107                  humidity, +1    0.001077\n",
      "52                  count_std_day    0.001056\n",
      "116                     atemp, +2    0.001049\n",
      "121                      temp, +2    0.001004\n",
      "102                      month_10    0.001003\n",
      "51                 count_mean_day    0.000993\n",
      "105                 windspeed, +1    0.000993\n",
      "7                       windspeed    0.000985\n",
      "20       casual_quantile_75_month    0.000961\n",
      "111                      temp, +1    0.000934\n",
      "19       casual_quantile_25_month    0.000909\n",
      "119                workingday, +2    0.000902\n",
      "117                  humidity, +2    0.000885\n",
      "34        count_quantile_75_month    0.000869\n",
      "110                   weather, +1    0.000840\n",
      "22       casual_quantile_90_month    0.000809\n",
      "103                      month_11    0.000795\n",
      "53               count_median_day    0.000776\n",
      "32             count_median_month    0.000733\n",
      "3                         weather    0.000704\n",
      "70                         hour_1    0.000657\n",
      "24           registered_std_month    0.000623\n",
      "44            registered_mean_day    0.000564\n",
      "59                      weather_3    0.000335\n",
      "62                       season_3    0.000304\n",
      "1                         holiday    0.000208\n",
      "97                        month_5    0.000200\n",
      "98                        month_6    0.000160\n",
      "79                        hour_10    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "45             registered_std_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "30               count_mean_month    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "76                         hour_7    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "63                       season_4    0.000000\n",
      "118                   holiday, +2    0.000000\n",
      "49     registered_quantile_10_day    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "60                      weather_4    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "104                      month_12    0.000000\n",
      "77                         hour_8    0.000000\n",
      "80                        hour_11    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "81                        hour_12    0.000000\n",
      "82                        hour_13    0.000000\n",
      "83                        hour_14    0.000000\n",
      "84                        hour_15    0.000000\n",
      "85                        hour_16    0.000000\n",
      "86                        hour_17    0.000000\n",
      "87                        hour_18    0.000000\n",
      "88                        hour_19    0.000000\n",
      "90                        hour_21    0.000000\n",
      "78                         hour_9    0.000000\n",
      "91                        hour_22    0.000000\n",
      "92                        hour_23    0.000000\n",
      "93                         year_2    0.000000\n",
      "42         casual_quantile_10_day    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "96                        month_4    0.000000\n",
      "99                        month_7    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "89                        hour_20    0.000000\n",
      "\n",
      "Fitting pipelines for count_original\n",
      "Maximum of the target: 977.0\n",
      "Avergae of the target: 191.47112524361472\n",
      "\n",
      "Fitting negative_count_pipeline_rf\n",
      "Fitting negative_count_pipeline_mlp\n",
      "negative_count_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "9                      registered    0.777907\n",
      "8                          casual    0.031006\n",
      "73                         hour_4    0.023812\n",
      "12                           hour    0.012979\n",
      "112                    casual, -1    0.011645\n",
      "114                     count, -1    0.010937\n",
      "122                    casual, -2    0.008223\n",
      "123                registered, -2    0.007848\n",
      "113                registered, -1    0.006769\n",
      "124                     count, -2    0.005316\n",
      "23          registered_mean_month    0.005024\n",
      "28   registered_quantile_10_month    0.004748\n",
      "10                           year    0.004013\n",
      "11                          month    0.003995\n",
      "2                      workingday    0.003535\n",
      "29   registered_quantile_90_month    0.003254\n",
      "33        count_quantile_25_month    0.003246\n",
      "31                count_std_month    0.002866\n",
      "15                      dayofweek    0.002838\n",
      "24           registered_std_month    0.002788\n",
      "16              casual_mean_month    0.002786\n",
      "13                      dayofyear    0.002377\n",
      "6                        humidity    0.002344\n",
      "18            casual_median_month    0.002276\n",
      "22       casual_quantile_90_month    0.002149\n",
      "5                           atemp    0.002085\n",
      "27   registered_quantile_75_month    0.001982\n",
      "58                      weather_2    0.001885\n",
      "74                         hour_5    0.001794\n",
      "26   registered_quantile_25_month    0.001785\n",
      "46          registered_median_day    0.001784\n",
      "30               count_mean_month    0.001752\n",
      "36        count_quantile_90_month    0.001714\n",
      "4                            temp    0.001679\n",
      "25        registered_median_month    0.001602\n",
      "51                 count_mean_day    0.001450\n",
      "38                 casual_std_day    0.001441\n",
      "116                     atemp, -2    0.001380\n",
      "71                         hour_2    0.001328\n",
      "17               casual_std_month    0.001306\n",
      "39              casual_median_day    0.001263\n",
      "96                        month_4    0.001249\n",
      "35        count_quantile_10_month    0.001243\n",
      "53               count_median_day    0.001153\n",
      "37                casual_mean_day    0.001126\n",
      "3                         weather    0.001118\n",
      "106                     atemp, -1    0.001081\n",
      "101                       month_9    0.001048\n",
      "107                  humidity, -1    0.001007\n",
      "111                      temp, -1    0.000990\n",
      "115                 windspeed, -2    0.000988\n",
      "117                  humidity, -2    0.000967\n",
      "19       casual_quantile_25_month    0.000958\n",
      "7                       windspeed    0.000951\n",
      "44            registered_mean_day    0.000947\n",
      "70                         hour_1    0.000922\n",
      "61                       season_2    0.000916\n",
      "102                      month_10    0.000859\n",
      "120                   weather, -2    0.000842\n",
      "52                  count_std_day    0.000775\n",
      "75                         hour_6    0.000770\n",
      "72                         hour_3    0.000765\n",
      "21       casual_quantile_10_month    0.000717\n",
      "121                      temp, -2    0.000711\n",
      "105                 windspeed, -1    0.000703\n",
      "119                workingday, -2    0.000696\n",
      "110                   weather, -1    0.000690\n",
      "109                workingday, -1    0.000626\n",
      "97                        month_5    0.000559\n",
      "57          count_quantile_90_day    0.000515\n",
      "34        count_quantile_75_month    0.000511\n",
      "0                          season    0.000507\n",
      "55          count_quantile_75_day    0.000451\n",
      "20       casual_quantile_75_month    0.000448\n",
      "108                   holiday, -1    0.000413\n",
      "98                        month_6    0.000407\n",
      "94                        month_2    0.000344\n",
      "62                       season_3    0.000118\n",
      "78                         hour_9    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "104                      month_12    0.000000\n",
      "60                      weather_4    0.000000\n",
      "59                      weather_3    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "76                         hour_7    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "49     registered_quantile_10_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "1                         holiday    0.000000\n",
      "45             registered_std_day    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "42         casual_quantile_10_day    0.000000\n",
      "118                   holiday, -2    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "32             count_median_month    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "103                      month_11    0.000000\n",
      "63                       season_4    0.000000\n",
      "79                        hour_10    0.000000\n",
      "89                        hour_20    0.000000\n",
      "80                        hour_11    0.000000\n",
      "81                        hour_12    0.000000\n",
      "82                        hour_13    0.000000\n",
      "83                        hour_14    0.000000\n",
      "84                        hour_15    0.000000\n",
      "85                        hour_16    0.000000\n",
      "86                        hour_17    0.000000\n",
      "87                        hour_18    0.000000\n",
      "88                        hour_19    0.000000\n",
      "90                        hour_21    0.000000\n",
      "100                       month_8    0.000000\n",
      "91                        hour_22    0.000000\n",
      "92                        hour_23    0.000000\n",
      "93                         year_2    0.000000\n",
      "77                         hour_8    0.000000\n",
      "95                        month_3    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "99                        month_7    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "\n",
      "Fitting positive_count_pipeline_rf\n",
      "Fitting positive_count_pipeline_mlp\n",
      "positive_count_original_pipeline_mlp\n",
      "                          feature  importance\n",
      "9                      registered    0.777713\n",
      "8                          casual    0.027217\n",
      "30               count_mean_month    0.025179\n",
      "73                         hour_4    0.023763\n",
      "12                           hour    0.011153\n",
      "112                    casual, +1    0.010487\n",
      "114                     count, +1    0.009383\n",
      "122                    casual, +2    0.008799\n",
      "113                registered, +1    0.006652\n",
      "31                count_std_month    0.005458\n",
      "123                registered, +2    0.005323\n",
      "124                     count, +2    0.005075\n",
      "26   registered_quantile_25_month    0.004328\n",
      "33        count_quantile_25_month    0.003360\n",
      "4                            temp    0.002446\n",
      "2                      workingday    0.002428\n",
      "20       casual_quantile_75_month    0.002425\n",
      "5                           atemp    0.002393\n",
      "36        count_quantile_90_month    0.002388\n",
      "6                        humidity    0.002148\n",
      "24           registered_std_month    0.002040\n",
      "96                        month_4    0.002032\n",
      "27   registered_quantile_75_month    0.001928\n",
      "74                         hour_5    0.001890\n",
      "10                           year    0.001880\n",
      "13                      dayofyear    0.001861\n",
      "38                 casual_std_day    0.001753\n",
      "23          registered_mean_month    0.001704\n",
      "25        registered_median_month    0.001657\n",
      "15                      dayofweek    0.001620\n",
      "111                      temp, +1    0.001605\n",
      "75                         hour_6    0.001598\n",
      "22       casual_quantile_90_month    0.001568\n",
      "109                workingday, +1    0.001551\n",
      "28   registered_quantile_10_month    0.001469\n",
      "17               casual_std_month    0.001402\n",
      "58                      weather_2    0.001279\n",
      "52                  count_std_day    0.001250\n",
      "37                casual_mean_day    0.001241\n",
      "116                     atemp, +2    0.001200\n",
      "106                     atemp, +1    0.001138\n",
      "29   registered_quantile_90_month    0.001134\n",
      "119                workingday, +2    0.001122\n",
      "107                  humidity, +1    0.001116\n",
      "16              casual_mean_month    0.001085\n",
      "35        count_quantile_10_month    0.001070\n",
      "3                         weather    0.001056\n",
      "0                          season    0.001024\n",
      "117                  humidity, +2    0.000984\n",
      "21       casual_quantile_10_month    0.000963\n",
      "121                      temp, +2    0.000963\n",
      "46          registered_median_day    0.000958\n",
      "120                   weather, +2    0.000936\n",
      "110                   weather, +1    0.000925\n",
      "71                         hour_2    0.000914\n",
      "72                         hour_3    0.000906\n",
      "57          count_quantile_90_day    0.000889\n",
      "7                       windspeed    0.000879\n",
      "18            casual_median_month    0.000878\n",
      "115                 windspeed, +2    0.000874\n",
      "51                 count_mean_day    0.000870\n",
      "108                   holiday, +1    0.000868\n",
      "39              casual_median_day    0.000789\n",
      "105                 windspeed, +1    0.000773\n",
      "70                         hour_1    0.000705\n",
      "59                      weather_3    0.000692\n",
      "11                          month    0.000628\n",
      "103                      month_11    0.000572\n",
      "32             count_median_month    0.000555\n",
      "19       casual_quantile_25_month    0.000418\n",
      "55          count_quantile_75_day    0.000399\n",
      "102                      month_10    0.000396\n",
      "34        count_quantile_75_month    0.000356\n",
      "44            registered_mean_day    0.000311\n",
      "101                       month_9    0.000280\n",
      "94                        month_2    0.000277\n",
      "95                        month_3    0.000270\n",
      "98                        month_6    0.000237\n",
      "53               count_median_day    0.000145\n",
      "42         casual_quantile_10_day    0.000000\n",
      "100                       month_8    0.000000\n",
      "97                        month_5    0.000000\n",
      "99                        month_7    0.000000\n",
      "48     registered_quantile_75_day    0.000000\n",
      "104                      month_12    0.000000\n",
      "41         casual_quantile_75_day    0.000000\n",
      "40         casual_quantile_25_day    0.000000\n",
      "92                        hour_23    0.000000\n",
      "118                   holiday, +2    0.000000\n",
      "14                     weekofyear    0.000000\n",
      "93                         year_2    0.000000\n",
      "86                        hour_17    0.000000\n",
      "91                        hour_22    0.000000\n",
      "45             registered_std_day    0.000000\n",
      "50     registered_quantile_90_day    0.000000\n",
      "47     registered_quantile_25_day    0.000000\n",
      "54          count_quantile_25_day    0.000000\n",
      "56          count_quantile_10_day    0.000000\n",
      "60                      weather_4    0.000000\n",
      "61                       season_2    0.000000\n",
      "1                         holiday    0.000000\n",
      "63                       season_4    0.000000\n",
      "64                    dayofweek_1    0.000000\n",
      "65                    dayofweek_2    0.000000\n",
      "66                    dayofweek_3    0.000000\n",
      "67                    dayofweek_4    0.000000\n",
      "68                    dayofweek_5    0.000000\n",
      "69                    dayofweek_6    0.000000\n",
      "43         casual_quantile_90_day    0.000000\n",
      "90                        hour_21    0.000000\n",
      "76                         hour_7    0.000000\n",
      "77                         hour_8    0.000000\n",
      "78                         hour_9    0.000000\n",
      "79                        hour_10    0.000000\n",
      "80                        hour_11    0.000000\n",
      "81                        hour_12    0.000000\n",
      "82                        hour_13    0.000000\n",
      "83                        hour_14    0.000000\n",
      "84                        hour_15    0.000000\n",
      "85                        hour_16    0.000000\n",
      "49     registered_quantile_10_day    0.000000\n",
      "87                        hour_18    0.000000\n",
      "88                        hour_19    0.000000\n",
      "89                        hour_20    0.000000\n",
      "62                       season_3    0.000000\n",
      "\n",
      "\n",
      "Predicting pipelines...\n",
      "\n",
      "Merging predictions...\n",
      "Merging predictions for negative_casual\n",
      "Merging predictions for positive_casual\n",
      "Maximum of the target prediction:  322.1616363587173\n",
      "Average of the target prediction:  36.3168217476036\n",
      "\n",
      "Merging predictions for negative_registered\n",
      "Merging predictions for positive_registered\n",
      "Maximum of the target prediction:  823.0074085782186\n",
      "Average of the target prediction:  158.8446383385049\n",
      "\n",
      "Merging predictions for negative_count\n",
      "Merging predictions for positive_count\n",
      "Maximum of the target prediction:  872.3571331218548\n",
      "Average of the target prediction:  196.06383923017202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_not_to_use = ['datetime', 'dataset', 'day']\n",
    "smoothed_columns = ['count']\n",
    "original_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "\n",
    "columns_not_to_use = columns_not_to_use + smoothed_columns + original_columns\n",
    "\n",
    "directions = ['negative', 'positive']\n",
    "rf = [True, True, True]\n",
    "mlp = [True, True, True]\n",
    "trees = [n, n, n]\n",
    "max_iter = 200\n",
    "hidden_layer_sizes = [(150, 150, 150), (250, 250, 250, 250), (200, 200, 200)]\n",
    "max_iter_no_change = [10, 15, 10]\n",
    "\n",
    "data_sample = training_data['positive']['X'].copy()\n",
    "data_sample = data_sample.drop(columns = columns_not_to_use, axis=1)\n",
    "\n",
    "# shuffle the data\n",
    "data_sample = data_sample.sample(frac=1, random_state=0)\n",
    "data_sample = data_sample[:2000]\n",
    "categorical_features = np.zeros((len(data_sample.columns),), dtype=bool)\n",
    "\n",
    "for col in data_sample.columns:\n",
    "    # check weather only 0 and 1 are present in the column\n",
    "    if len(data_sample[col].unique()) == 2:\n",
    "        # if so, append the column to the list of categorical features\n",
    "        categorical_features[data_sample.columns.get_loc(col)] = True\n",
    "\n",
    "\n",
    "train_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "test_columns = train_columns\n",
    "\n",
    "\n",
    "# create the pipelines\n",
    "pipelines = create_pipelines(train_columns, directions, \n",
    "                             trees, hidden_layer_sizes,\n",
    "                             max_iter_no_change, categorical_features,\n",
    "                             rf=rf, mlp=mlp, max_iter=max_iter)\n",
    "\n",
    "\n",
    "# fit the pipelines\n",
    "fitted_pipelines = fit_pipelines(pipelines, triaining_data_count,\n",
    "                                 train_columns, columns_not_to_use,\n",
    "                                 directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# predict the pipelines\n",
    "predictions, dataframes = predict_pipelines(fitted_pipelines, triaining_data_count, \n",
    "                                            train_columns, test_columns, \n",
    "                                            columns_not_to_use, test_period, \n",
    "                                            maximum_day, directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# evaluate the pipelines\n",
    "triaining_data_count2 = merge_predictions(predictions, triaining_data_count, test_columns, directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the predictions for count from the training data\n",
    "count_predictions = triaining_data_count2['positive']['y']['count']\n",
    "\n",
    "# save the predictions into a csv file with the datetime column\n",
    "count_predictions = pd.concat([triaining_data_count2['positive']['y']['datetime'], count_predictions], axis=1)\n",
    "\n",
    "# set negative values to zero\n",
    "count_predictions.loc[count_predictions['count'] < 0, 'count'] = 0\n",
    "\n",
    "count_predictions.to_csv('../../data/processed/count_predictions1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>5.542577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>5.242131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>5.105481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>4.119505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>3.284797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-20 05:00:00</td>\n",
       "      <td>1.288510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-20 06:00:00</td>\n",
       "      <td>7.066305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-20 07:00:00</td>\n",
       "      <td>89.949039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-20 08:00:00</td>\n",
       "      <td>228.670969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-20 09:00:00</td>\n",
       "      <td>123.608777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-01-20 10:00:00</td>\n",
       "      <td>28.549901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-01-20 11:00:00</td>\n",
       "      <td>42.460308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011-01-20 12:00:00</td>\n",
       "      <td>61.276854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01-20 13:00:00</td>\n",
       "      <td>69.464530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-01-20 14:00:00</td>\n",
       "      <td>55.189986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-01-20 15:00:00</td>\n",
       "      <td>51.789361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011-01-20 16:00:00</td>\n",
       "      <td>100.463766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011-01-20 17:00:00</td>\n",
       "      <td>208.376870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011-01-20 18:00:00</td>\n",
       "      <td>173.027774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-01-20 19:00:00</td>\n",
       "      <td>113.695620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime       count\n",
       "0   2011-01-20 00:00:00    5.542577\n",
       "1   2011-01-20 01:00:00    5.242131\n",
       "2   2011-01-20 02:00:00    5.105481\n",
       "3   2011-01-20 03:00:00    4.119505\n",
       "4   2011-01-20 04:00:00    3.284797\n",
       "5   2011-01-20 05:00:00    1.288510\n",
       "6   2011-01-20 06:00:00    7.066305\n",
       "7   2011-01-20 07:00:00   89.949039\n",
       "8   2011-01-20 08:00:00  228.670969\n",
       "9   2011-01-20 09:00:00  123.608777\n",
       "10  2011-01-20 10:00:00   28.549901\n",
       "11  2011-01-20 11:00:00   42.460308\n",
       "12  2011-01-20 12:00:00   61.276854\n",
       "13  2011-01-20 13:00:00   69.464530\n",
       "14  2011-01-20 14:00:00   55.189986\n",
       "15  2011-01-20 15:00:00   51.789361\n",
       "16  2011-01-20 16:00:00  100.463766\n",
       "17  2011-01-20 17:00:00  208.376870\n",
       "18  2011-01-20 18:00:00  173.027774\n",
       "19  2011-01-20 19:00:00  113.695620"
      ]
     },
     "execution_count": 1457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the predictions1.csv file\n",
    "count_predictions = pd.read_csv('../../data/processed/count_predictions1.csv')\n",
    "\n",
    "count_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_pipelines() missing 1 required positional argument: 'categorical_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1458], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m test_columns \u001b[38;5;241m=\u001b[39m train_columns\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# create the pipelines\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m pipelines \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_pipelines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_iter_no_change\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# fit the pipelines\u001b[39;00m\n\u001b[1;32m     41\u001b[0m fitted_pipelines \u001b[38;5;241m=\u001b[39m fit_pipelines(pipelines, triaining_data_count2, \n\u001b[1;32m     42\u001b[0m                                  train_columns, columns_not_to_use,\n\u001b[1;32m     43\u001b[0m                                  directions, rf\u001b[38;5;241m=\u001b[39mrf, mlp\u001b[38;5;241m=\u001b[39mmlp)\n",
      "\u001b[0;31mTypeError\u001b[0m: create_pipelines() missing 1 required positional argument: 'categorical_features'"
     ]
    }
   ],
   "source": [
    "columns_not_to_use = ['datetime', 'dataset', 'day', 'month']\n",
    "smoothed_columns = []\n",
    "original_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "\n",
    "columns_not_to_use = columns_not_to_use + smoothed_columns + original_columns\n",
    "\n",
    "directions = ['negative', 'positive']\n",
    "rf = [True, True, True]\n",
    "mlp = [True, True, True]\n",
    "trees = [n, n, n]\n",
    "max_iter = 2000\n",
    "hidden_layer_sizes = [(150, 150, 150), (250, 250, 250, 250), (200, 200, 200)]\n",
    "max_iter_no_change = [10, 15, 10]\n",
    "\n",
    "data_sample = training_data['positive']['X'].copy()\n",
    "data_sample = data_sample.drop(columns = columns_not_to_use, axis=1)\n",
    "\n",
    "# shuffle the data\n",
    "data_sample = data_sample.sample(frac=1, random_state=0)\n",
    "data_sample = data_sample[:2000]\n",
    "categorical_features = np.zeros((len(data_sample.columns),), dtype=bool)\n",
    "\n",
    "for col in data_sample.columns:\n",
    "    # check weather only 0 and 1 are present in the column\n",
    "    if len(data_sample[col].unique()) == 2:\n",
    "        # if so, append the column to the list of categorical features\n",
    "        categorical_features[data_sample.columns.get_loc(col)] = True\n",
    "\n",
    "\n",
    "train_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "test_columns = train_columns\n",
    "\n",
    "\n",
    "# create the pipelines\n",
    "pipelines = create_pipelines(train_columns, directions, \n",
    "                             trees, hidden_layer_sizes,\n",
    "                             max_iter_no_change, \n",
    "                             rf=rf, mlp=mlp, max_iter=max_iter)\n",
    "\n",
    "# fit the pipelines\n",
    "fitted_pipelines = fit_pipelines(pipelines, triaining_data_count2, \n",
    "                                 train_columns, columns_not_to_use,\n",
    "                                 directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# predict the pipelines\n",
    "predictions, dataframes = predict_pipelines(fitted_pipelines, triaining_data_count2, \n",
    "                                            train_columns, test_columns, \n",
    "                                            columns_not_to_use, test_period, \n",
    "                                            maximum_day, directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# evaluate the pipelines\n",
    "triaining_data_count3 = merge_predictions(predictions, triaining_data_count2, test_columns, directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the predictions for count from the training data\n",
    "count_predictions = triaining_data_count3['positive']['y']['count']\n",
    "\n",
    "# save the predictions into a csv file with the datetime column\n",
    "count_predictions = pd.concat([triaining_data_count3['positive']['y']['datetime'], count_predictions], axis=1)\n",
    "\n",
    "# set negative values to zero\n",
    "count_predictions.loc[count_predictions['count'] < 0, 'count'] = 0\n",
    "\n",
    "count_predictions.to_csv('../../data/processed/count_predictions2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting pipelines for casual_original\n",
      "Maximum of the target: 367.0\n",
      "Avergae of the target: 36.023899887167914\n",
      "\n",
      "Fitting negative_casual_pipeline_rf\n",
      "Fitting negative_casual_pipeline_mlp\n",
      "Fitting positive_casual_pipeline_rf\n",
      "Fitting positive_casual_pipeline_mlp\n",
      "Fitting pipelines for registered_original\n",
      "Maximum of the target: 886.0\n",
      "Avergae of the target: 155.4472253564468\n",
      "\n",
      "Fitting negative_registered_pipeline_rf\n",
      "Fitting negative_registered_pipeline_mlp\n",
      "Fitting positive_registered_pipeline_rf\n",
      "Fitting positive_registered_pipeline_mlp\n",
      "Fitting pipelines for count_original\n",
      "Maximum of the target: 977.0\n",
      "Avergae of the target: 191.47112524361472\n",
      "\n",
      "Fitting negative_count_pipeline_rf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1191], line 27\u001b[0m\n\u001b[1;32m     21\u001b[0m pipelines \u001b[38;5;241m=\u001b[39m create_pipelines(train_columns, directions, \n\u001b[1;32m     22\u001b[0m                              trees, hidden_layer_sizes,\n\u001b[1;32m     23\u001b[0m                              max_iter_no_change, \n\u001b[1;32m     24\u001b[0m                              rf\u001b[38;5;241m=\u001b[39mrf, mlp\u001b[38;5;241m=\u001b[39mmlp, max_iter\u001b[38;5;241m=\u001b[39mmax_iter)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# fit the pipelines\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m fitted_pipelines \u001b[38;5;241m=\u001b[39m \u001b[43mfit_pipelines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriaining_data_count3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtrain_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_not_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# predict the pipelines\u001b[39;00m\n\u001b[1;32m     32\u001b[0m predictions, dataframes \u001b[38;5;241m=\u001b[39m predict_pipelines(fitted_pipelines, triaining_data_count3, \n\u001b[1;32m     33\u001b[0m                                             train_columns, test_columns, \n\u001b[1;32m     34\u001b[0m                                             columns_not_to_use, test_period, \n\u001b[1;32m     35\u001b[0m                                             maximum_day, directions, rf\u001b[38;5;241m=\u001b[39mrf, mlp\u001b[38;5;241m=\u001b[39mmlp)\n",
      "Cell \u001b[0;32mIn[1175], line 37\u001b[0m, in \u001b[0;36mfit_pipelines\u001b[0;34m(pipelines, train_data, target_columns, columns_not_to_use, directions, rf, mlp)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m pipeline_rf \u001b[38;5;241m=\u001b[39m pipelines[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m \u001b[43mpipeline_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# save the fitted pipeline\u001b[39;00m\n\u001b[1;32m     40\u001b[0m fitted_pipelines[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pipeline_rf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipeline_rf\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 475\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:908\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_):\n\u001b[1;32m    889\u001b[0m     grower \u001b[38;5;241m=\u001b[39m TreeGrower(\n\u001b[1;32m    890\u001b[0m         X_binned\u001b[38;5;241m=\u001b[39mX_binned_train,\n\u001b[1;32m    891\u001b[0m         gradients\u001b[38;5;241m=\u001b[39mg_view[:, k],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    906\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    907\u001b[0m     )\n\u001b[0;32m--> 908\u001b[0m     \u001b[43mgrower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m     acc_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_apply_split_time\n\u001b[1;32m    911\u001b[0m     acc_find_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_find_split_time\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:376\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_shrinkage()\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:613\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_split_left:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_best_split_and_push\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_child_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_split_right:\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_best_split_and_push(right_child_node)\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/bike_sharing_demand/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:446\u001b[0m, in \u001b[0;36mTreeGrower._compute_best_split_and_push\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_best_split_and_push\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the best possible split (SplitInfo) of a given node.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    Also push it in the heap of splittable nodes if gain isn't zero.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    (min_hessians_to_split, min_gain_to_split, min_samples_leaf)\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     node\u001b[38;5;241m.\u001b[39msplit_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_node_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistograms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistograms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43msum_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msum_hessians\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_hessians\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallowed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39msplit_info\u001b[38;5;241m.\u001b[39mgain \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# no valid split\u001b[39;00m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_leaf(node)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns_not_to_use = ['datetime', 'dataset']\n",
    "smoothed_columns = []\n",
    "original_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "\n",
    "columns_not_to_use = columns_not_to_use + smoothed_columns + original_columns\n",
    "\n",
    "directions = ['negative', 'positive']\n",
    "rf = [True, True, True]\n",
    "mlp = [True, True, True]\n",
    "trees = [n, n, n]\n",
    "max_iter = 2000\n",
    "hidden_layer_sizes = [(150, 150, 150), (250, 250, 250, 250), (200, 200, 200)]\n",
    "max_iter_no_change = [10, 15, 10]\n",
    "\n",
    "\n",
    "train_columns = ['casual_original', 'registered_original', 'count_original']\n",
    "test_columns = train_columns\n",
    "\n",
    "\n",
    "# create the pipelines\n",
    "pipelines = create_pipelines(train_columns, directions, \n",
    "                             trees, hidden_layer_sizes,\n",
    "                             max_iter_no_change, \n",
    "                             rf=rf, mlp=mlp, max_iter=max_iter)\n",
    "\n",
    "# fit the pipelines\n",
    "fitted_pipelines = fit_pipelines(pipelines, triaining_data_count3, \n",
    "                                 train_columns, columns_not_to_use,\n",
    "                                 directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# predict the pipelines\n",
    "predictions, dataframes = predict_pipelines(fitted_pipelines, triaining_data_count3, \n",
    "                                            train_columns, test_columns, \n",
    "                                            columns_not_to_use, test_period, \n",
    "                                            maximum_day, directions, rf=rf, mlp=mlp)\n",
    "\n",
    "# evaluate the pipelines\n",
    "triaining_data_count4 = merge_predictions(predictions, triaining_data_count3, test_columns, directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the predictions for count from the training data\n",
    "count_predictions = triaining_data_count4['positive']['y']['count']\n",
    "\n",
    "# save the predictions into a csv file with the datetime column\n",
    "count_predictions = pd.concat([triaining_data_count4['positive']['y']['datetime'], count_predictions], axis=1)\n",
    "\n",
    "# set negative values to zero\n",
    "count_predictions.loc[count_predictions['count'] < 0, 'count'] = 0\n",
    "\n",
    "count_predictions.to_csv('../../data/processed/count_predictions3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>72.467480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>50.295541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>56.667174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>42.309496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>34.552143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2011-01-20 05:00:00</td>\n",
       "      <td>32.216073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2011-01-20 06:00:00</td>\n",
       "      <td>40.736981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2011-01-20 07:00:00</td>\n",
       "      <td>91.925647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2011-01-20 08:00:00</td>\n",
       "      <td>615.201044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2011-01-20 09:00:00</td>\n",
       "      <td>172.704211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2011-01-20 10:00:00</td>\n",
       "      <td>20.781155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2011-01-20 11:00:00</td>\n",
       "      <td>90.807830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2011-01-20 12:00:00</td>\n",
       "      <td>178.325060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2011-01-20 13:00:00</td>\n",
       "      <td>181.075154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2011-01-20 14:00:00</td>\n",
       "      <td>112.207451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2011-01-20 15:00:00</td>\n",
       "      <td>102.023798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2011-01-20 16:00:00</td>\n",
       "      <td>101.071298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2011-01-20 17:00:00</td>\n",
       "      <td>418.792621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2011-01-20 18:00:00</td>\n",
       "      <td>239.982368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2011-01-20 19:00:00</td>\n",
       "      <td>136.370708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2011-01-20 20:00:00</td>\n",
       "      <td>130.836390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2011-01-20 21:00:00</td>\n",
       "      <td>106.823243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2011-01-20 22:00:00</td>\n",
       "      <td>115.816488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2011-01-20 23:00:00</td>\n",
       "      <td>94.918497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2011-01-21 00:00:00</td>\n",
       "      <td>60.759880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2011-01-21 01:00:00</td>\n",
       "      <td>52.753092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2011-01-21 02:00:00</td>\n",
       "      <td>47.397671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2011-01-21 03:00:00</td>\n",
       "      <td>44.701525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2011-01-21 04:00:00</td>\n",
       "      <td>31.905632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2011-01-21 05:00:00</td>\n",
       "      <td>35.069146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2011-01-21 06:00:00</td>\n",
       "      <td>38.959775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2011-01-21 07:00:00</td>\n",
       "      <td>42.650197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2011-01-21 08:00:00</td>\n",
       "      <td>633.770604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2011-01-21 09:00:00</td>\n",
       "      <td>149.722979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2011-01-21 10:00:00</td>\n",
       "      <td>11.593908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2011-01-21 11:00:00</td>\n",
       "      <td>83.614754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2011-01-21 12:00:00</td>\n",
       "      <td>114.101950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2011-01-21 13:00:00</td>\n",
       "      <td>111.988788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2011-01-21 14:00:00</td>\n",
       "      <td>86.253404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2011-01-21 15:00:00</td>\n",
       "      <td>64.228831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2011-01-21 16:00:00</td>\n",
       "      <td>54.923999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2011-01-21 17:00:00</td>\n",
       "      <td>255.144850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2011-01-21 18:00:00</td>\n",
       "      <td>180.817231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2011-01-21 19:00:00</td>\n",
       "      <td>75.856925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2011-01-21 20:00:00</td>\n",
       "      <td>101.700847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2011-01-21 21:00:00</td>\n",
       "      <td>123.907491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2011-01-21 22:00:00</td>\n",
       "      <td>114.761041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2011-01-21 23:00:00</td>\n",
       "      <td>87.478932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2011-01-22 00:00:00</td>\n",
       "      <td>88.823015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2011-01-22 01:00:00</td>\n",
       "      <td>86.572767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime       count\n",
       "431 2011-01-20 00:00:00   72.467480\n",
       "432 2011-01-20 01:00:00   50.295541\n",
       "433 2011-01-20 02:00:00   56.667174\n",
       "434 2011-01-20 03:00:00   42.309496\n",
       "435 2011-01-20 04:00:00   34.552143\n",
       "436 2011-01-20 05:00:00   32.216073\n",
       "437 2011-01-20 06:00:00   40.736981\n",
       "438 2011-01-20 07:00:00   91.925647\n",
       "439 2011-01-20 08:00:00  615.201044\n",
       "440 2011-01-20 09:00:00  172.704211\n",
       "441 2011-01-20 10:00:00   20.781155\n",
       "442 2011-01-20 11:00:00   90.807830\n",
       "443 2011-01-20 12:00:00  178.325060\n",
       "444 2011-01-20 13:00:00  181.075154\n",
       "445 2011-01-20 14:00:00  112.207451\n",
       "446 2011-01-20 15:00:00  102.023798\n",
       "447 2011-01-20 16:00:00  101.071298\n",
       "448 2011-01-20 17:00:00  418.792621\n",
       "449 2011-01-20 18:00:00  239.982368\n",
       "450 2011-01-20 19:00:00  136.370708\n",
       "451 2011-01-20 20:00:00  130.836390\n",
       "452 2011-01-20 21:00:00  106.823243\n",
       "453 2011-01-20 22:00:00  115.816488\n",
       "454 2011-01-20 23:00:00   94.918497\n",
       "455 2011-01-21 00:00:00   60.759880\n",
       "456 2011-01-21 01:00:00   52.753092\n",
       "457 2011-01-21 02:00:00   47.397671\n",
       "458 2011-01-21 03:00:00   44.701525\n",
       "459 2011-01-21 04:00:00   31.905632\n",
       "460 2011-01-21 05:00:00   35.069146\n",
       "461 2011-01-21 06:00:00   38.959775\n",
       "462 2011-01-21 07:00:00   42.650197\n",
       "463 2011-01-21 08:00:00  633.770604\n",
       "464 2011-01-21 09:00:00  149.722979\n",
       "465 2011-01-21 10:00:00   11.593908\n",
       "466 2011-01-21 11:00:00   83.614754\n",
       "467 2011-01-21 12:00:00  114.101950\n",
       "468 2011-01-21 13:00:00  111.988788\n",
       "469 2011-01-21 14:00:00   86.253404\n",
       "470 2011-01-21 15:00:00   64.228831\n",
       "471 2011-01-21 16:00:00   54.923999\n",
       "472 2011-01-21 17:00:00  255.144850\n",
       "473 2011-01-21 18:00:00  180.817231\n",
       "474 2011-01-21 19:00:00   75.856925\n",
       "475 2011-01-21 20:00:00  101.700847\n",
       "476 2011-01-21 21:00:00  123.907491\n",
       "477 2011-01-21 22:00:00  114.761041\n",
       "478 2011-01-21 23:00:00   87.478932\n",
       "479 2011-01-22 00:00:00   88.823015\n",
       "480 2011-01-22 01:00:00   86.572767"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_predictions.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>72.467480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>50.295541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>56.667174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>42.309496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>34.552143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2011-01-20 05:00:00</td>\n",
       "      <td>32.216073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2011-01-20 06:00:00</td>\n",
       "      <td>40.736981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2011-01-20 07:00:00</td>\n",
       "      <td>91.925647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2011-01-20 08:00:00</td>\n",
       "      <td>615.201044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2011-01-20 09:00:00</td>\n",
       "      <td>172.704211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2011-01-20 10:00:00</td>\n",
       "      <td>20.781155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2011-01-20 11:00:00</td>\n",
       "      <td>90.807830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2011-01-20 12:00:00</td>\n",
       "      <td>178.325060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2011-01-20 13:00:00</td>\n",
       "      <td>181.075154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2011-01-20 14:00:00</td>\n",
       "      <td>112.207451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2011-01-20 15:00:00</td>\n",
       "      <td>102.023798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2011-01-20 16:00:00</td>\n",
       "      <td>101.071298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2011-01-20 17:00:00</td>\n",
       "      <td>418.792621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2011-01-20 18:00:00</td>\n",
       "      <td>239.982368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2011-01-20 19:00:00</td>\n",
       "      <td>136.370708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2011-01-20 20:00:00</td>\n",
       "      <td>130.836390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2011-01-20 21:00:00</td>\n",
       "      <td>106.823243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2011-01-20 22:00:00</td>\n",
       "      <td>115.816488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2011-01-20 23:00:00</td>\n",
       "      <td>94.918497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2011-01-21 00:00:00</td>\n",
       "      <td>60.759880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2011-01-21 01:00:00</td>\n",
       "      <td>52.753092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2011-01-21 02:00:00</td>\n",
       "      <td>47.397671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2011-01-21 03:00:00</td>\n",
       "      <td>44.701525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2011-01-21 04:00:00</td>\n",
       "      <td>31.905632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2011-01-21 05:00:00</td>\n",
       "      <td>35.069146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2011-01-21 06:00:00</td>\n",
       "      <td>38.959775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2011-01-21 07:00:00</td>\n",
       "      <td>42.650197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2011-01-21 08:00:00</td>\n",
       "      <td>633.770604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2011-01-21 09:00:00</td>\n",
       "      <td>149.722979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2011-01-21 10:00:00</td>\n",
       "      <td>11.593908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2011-01-21 11:00:00</td>\n",
       "      <td>83.614754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2011-01-21 12:00:00</td>\n",
       "      <td>114.101950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2011-01-21 13:00:00</td>\n",
       "      <td>111.988788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2011-01-21 14:00:00</td>\n",
       "      <td>86.253404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2011-01-21 15:00:00</td>\n",
       "      <td>64.228831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2011-01-21 16:00:00</td>\n",
       "      <td>54.923999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2011-01-21 17:00:00</td>\n",
       "      <td>255.144850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2011-01-21 18:00:00</td>\n",
       "      <td>180.817231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2011-01-21 19:00:00</td>\n",
       "      <td>75.856925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2011-01-21 20:00:00</td>\n",
       "      <td>101.700847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2011-01-21 21:00:00</td>\n",
       "      <td>123.907491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2011-01-21 22:00:00</td>\n",
       "      <td>114.761041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2011-01-21 23:00:00</td>\n",
       "      <td>87.478932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2011-01-22 00:00:00</td>\n",
       "      <td>88.823015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2011-01-22 01:00:00</td>\n",
       "      <td>86.572767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime       count\n",
       "431 2011-01-20 00:00:00   72.467480\n",
       "432 2011-01-20 01:00:00   50.295541\n",
       "433 2011-01-20 02:00:00   56.667174\n",
       "434 2011-01-20 03:00:00   42.309496\n",
       "435 2011-01-20 04:00:00   34.552143\n",
       "436 2011-01-20 05:00:00   32.216073\n",
       "437 2011-01-20 06:00:00   40.736981\n",
       "438 2011-01-20 07:00:00   91.925647\n",
       "439 2011-01-20 08:00:00  615.201044\n",
       "440 2011-01-20 09:00:00  172.704211\n",
       "441 2011-01-20 10:00:00   20.781155\n",
       "442 2011-01-20 11:00:00   90.807830\n",
       "443 2011-01-20 12:00:00  178.325060\n",
       "444 2011-01-20 13:00:00  181.075154\n",
       "445 2011-01-20 14:00:00  112.207451\n",
       "446 2011-01-20 15:00:00  102.023798\n",
       "447 2011-01-20 16:00:00  101.071298\n",
       "448 2011-01-20 17:00:00  418.792621\n",
       "449 2011-01-20 18:00:00  239.982368\n",
       "450 2011-01-20 19:00:00  136.370708\n",
       "451 2011-01-20 20:00:00  130.836390\n",
       "452 2011-01-20 21:00:00  106.823243\n",
       "453 2011-01-20 22:00:00  115.816488\n",
       "454 2011-01-20 23:00:00   94.918497\n",
       "455 2011-01-21 00:00:00   60.759880\n",
       "456 2011-01-21 01:00:00   52.753092\n",
       "457 2011-01-21 02:00:00   47.397671\n",
       "458 2011-01-21 03:00:00   44.701525\n",
       "459 2011-01-21 04:00:00   31.905632\n",
       "460 2011-01-21 05:00:00   35.069146\n",
       "461 2011-01-21 06:00:00   38.959775\n",
       "462 2011-01-21 07:00:00   42.650197\n",
       "463 2011-01-21 08:00:00  633.770604\n",
       "464 2011-01-21 09:00:00  149.722979\n",
       "465 2011-01-21 10:00:00   11.593908\n",
       "466 2011-01-21 11:00:00   83.614754\n",
       "467 2011-01-21 12:00:00  114.101950\n",
       "468 2011-01-21 13:00:00  111.988788\n",
       "469 2011-01-21 14:00:00   86.253404\n",
       "470 2011-01-21 15:00:00   64.228831\n",
       "471 2011-01-21 16:00:00   54.923999\n",
       "472 2011-01-21 17:00:00  255.144850\n",
       "473 2011-01-21 18:00:00  180.817231\n",
       "474 2011-01-21 19:00:00   75.856925\n",
       "475 2011-01-21 20:00:00  101.700847\n",
       "476 2011-01-21 21:00:00  123.907491\n",
       "477 2011-01-21 22:00:00  114.761041\n",
       "478 2011-01-21 23:00:00   87.478932\n",
       "479 2011-01-22 00:00:00   88.823015\n",
       "480 2011-01-22 01:00:00   86.572767"
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_predictions.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
